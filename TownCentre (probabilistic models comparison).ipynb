{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Lambda, Flatten\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Model, Sequential\n",
    "from keras.objectives import binary_crossentropy\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "from models import vgg\n",
    "from utils.angles import deg2bit, bit2deg\n",
    "from utils.losses import maad_from_deg \n",
    "from utils.losses import bessel_approx_np, bessel_approx_tf\n",
    "from utils.losses import von_mises_log_likelihood_np, von_mises_log_likelihood_tf\n",
    "from utils.towncentre import load_towncentre\n",
    "from utils.experiements import get_experiment_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtr, ytr_deg, xte, yte_deg = load_towncentre('data/TownCentre.pkl.gz', canonical_split=True)\n",
    "image_height, image_width = xtr.shape[1], xtr.shape[2]\n",
    "ytr_bit = deg2bit(ytr_deg)\n",
    "yte_bit = deg2bit(yte_deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#x_tf = tf.placeholder(tf.float32, shape=[None, 3, image_width, image_height])\n",
    "mu_pred_tf = tf.placeholder(tf.float32, shape=[None, 2])\n",
    "log_kappa_tf = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "y_true_tf = tf.placeholder(tf.float32, shape=[None, 2])\n",
    "y_pred_tf = tf.concat([mu_pred_tf, log_kappa_tf], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def von_mises_neg_log_likelihood_keras(y_true, y_pred):\n",
    "    mu_pred = y_pred[:,0:2]\n",
    "    log_kappa_pred = y_pred[:, 2:]\n",
    "    return -von_mises_log_likelihood_tf(y_true, mu_pred, log_kappa_pred, input_type='biternion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss1= -von_mises_log_likelihood_tf(y_true_tf, mu_pred_tf, log_kappa_tf, input_type='biternion')\n",
    "loss2 = von_mises_neg_log_likelihood_keras(y_true_tf, y_pred_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_kappa = np.ones([ytr_bit.shape[0], 1])*0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    log_likelighood1 = sess.run(loss1, feed_dict={y_true_tf:ytr_bit[0:100], mu_pred_tf:ytr_bit[0:100], log_kappa_tf:log_kappa[0:100]})\n",
    "    log_likelighood2 = sess.run(loss2, feed_dict={y_true_tf:ytr_bit[0:100], mu_pred_tf:ytr_bit[0:100], log_kappa_tf:log_kappa[0:100]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0737537"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_likelighood1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0737537"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_likelighood2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0737913709802149"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "von_mises_log_likelihood_np(ytr_bit[0:100], ytr_bit[0:100], log_kappa[0:100], input_type='biternion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = Input(shape=[50,50,3])\n",
    "vgg_x = vgg.vgg_model(final_layer=False,\n",
    "                      image_height=50,\n",
    "                      image_width=50)(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mu = Lambda(lambda x: K.l2_normalize(x, axis=1))(Dense(2)(vgg_x))\n",
    "log_sigma = Input(shape=[1]) #Dense(1)(vgg_x)\n",
    "mu_log_sigma = concatenate([mu, log_sigma])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "biternion_vgg_prob = Model([X, log_sigma], mu_log_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'input_2:0' shape=(?, 50, 50, 3) dtype=float32>,\n",
       " <tf.Tensor 'input_3:0' shape=(?, 1) dtype=float32>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biternion_vgg_prob.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "biternion_vgg_prob.compile(loss=von_mises_neg_log_likelihood_keras,\n",
    "                           optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7002 samples, validate on 778 samples\n",
      "Epoch 1/50\n",
      "7002/7002 [==============================] - 48s - loss: 1.3098 - val_loss: 1.6380\n",
      "Epoch 2/50\n",
      "7002/7002 [==============================] - 48s - loss: 1.2888 - val_loss: 1.5227\n",
      "Epoch 3/50\n",
      "7002/7002 [==============================] - 48s - loss: 1.2764 - val_loss: 1.5227\n",
      "Epoch 4/50\n",
      "7002/7002 [==============================] - 48s - loss: 1.3225 - val_loss: 1.7930\n",
      "Epoch 5/50\n",
      "7002/7002 [==============================] - 47s - loss: 1.3089 - val_loss: 1.5553\n",
      "Epoch 6/50\n",
      "7002/7002 [==============================] - 48s - loss: 1.2985 - val_loss: 1.4316\n",
      "Epoch 7/50\n",
      "7002/7002 [==============================] - 48s - loss: 1.2698 - val_loss: 1.4393\n",
      "Epoch 8/50\n",
      "7002/7002 [==============================] - 48s - loss: 1.2713 - val_loss: 1.4670\n",
      "Epoch 9/50\n",
      "7002/7002 [==============================] - 47s - loss: 1.2618 - val_loss: 1.4612\n",
      "Epoch 10/50\n",
      "7002/7002 [==============================] - 47s - loss: 1.2632 - val_loss: 1.5616\n",
      "Epoch 11/50\n",
      "7002/7002 [==============================] - 47s - loss: 1.2509 - val_loss: 1.4747\n",
      "Epoch 12/50\n",
      "7002/7002 [==============================] - 47s - loss: 1.2665 - val_loss: 1.4224\n",
      "Epoch 13/50\n",
      "7002/7002 [==============================] - 47s - loss: 1.2883 - val_loss: 1.4995\n",
      "Epoch 14/50\n",
      "7002/7002 [==============================] - 47s - loss: 1.2658 - val_loss: 1.7285\n",
      "Epoch 15/50\n",
      "7002/7002 [==============================] - 47s - loss: 1.2501 - val_loss: 1.7515\n",
      "Epoch 16/50\n",
      "7002/7002 [==============================] - 47s - loss: 1.2621 - val_loss: 1.6788\n",
      "Epoch 17/50\n",
      "7002/7002 [==============================] - 47s - loss: 1.2426 - val_loss: 1.4675\n",
      "Epoch 18/50\n",
      "7002/7002 [==============================] - 47s - loss: 1.2385 - val_loss: 1.4559\n",
      "Epoch 19/50\n",
      "7002/7002 [==============================] - 47s - loss: 1.3295 - val_loss: 1.8026\n",
      "Epoch 20/50\n",
      "7002/7002 [==============================] - 48s - loss: 1.2947 - val_loss: 1.7319\n",
      "Epoch 21/50\n",
      "7002/7002 [==============================] - 48s - loss: 1.2805 - val_loss: 1.4516\n",
      "Epoch 22/50\n",
      "7002/7002 [==============================] - 47s - loss: 1.2532 - val_loss: 1.5001\n",
      "Epoch 23/50\n",
      "7002/7002 [==============================] - 48s - loss: 1.2659 - val_loss: 1.5609\n",
      "Epoch 24/50\n",
      "7002/7002 [==============================] - 47s - loss: 1.3226 - val_loss: 1.6043\n",
      "Epoch 25/50\n",
      "7002/7002 [==============================] - 47s - loss: 1.2604 - val_loss: 1.5776\n",
      "Epoch 26/50\n",
      "7002/7002 [==============================] - 47s - loss: 1.2953 - val_loss: 1.7851\n",
      "Epoch 27/50\n",
      "7002/7002 [==============================] - 47s - loss: 1.2704 - val_loss: 1.4244\n",
      "Epoch 28/50\n",
      "7002/7002 [==============================] - 47s - loss: 1.2461 - val_loss: 1.5204\n",
      "Epoch 29/50\n",
      "7002/7002 [==============================] - 47s - loss: 1.2320 - val_loss: 1.4527\n",
      "Epoch 30/50\n",
      "7002/7002 [==============================] - 47s - loss: 1.2290 - val_loss: 1.5603\n",
      "Epoch 31/50\n",
      "7002/7002 [==============================] - 47s - loss: 1.2161 - val_loss: 1.4063\n",
      "Epoch 32/50\n",
      "7002/7002 [==============================] - 47s - loss: 1.2163 - val_loss: 1.6432\n",
      "Epoch 33/50\n",
      "7002/7002 [==============================] - 47s - loss: 1.2320 - val_loss: 1.5201\n",
      "Epoch 34/50\n",
      "7002/7002 [==============================] - 47s - loss: 1.3613 - val_loss: 2.0448\n",
      "Epoch 35/50\n",
      "7002/7002 [==============================] - 47s - loss: 1.3708 - val_loss: 1.6035\n",
      "Epoch 36/50\n",
      "7002/7002 [==============================] - 47s - loss: 1.3022 - val_loss: 1.5891\n",
      "Epoch 37/50\n",
      "7002/7002 [==============================] - 47s - loss: 1.2720 - val_loss: 1.6002\n",
      "Epoch 38/50\n",
      "7002/7002 [==============================] - 47s - loss: 1.2717 - val_loss: 1.5967\n",
      "Epoch 39/50\n",
      "7002/7002 [==============================] - 47s - loss: 1.2715 - val_loss: 1.4690\n",
      "Epoch 40/50\n",
      "7002/7002 [==============================] - 47s - loss: 1.2590 - val_loss: 1.6745\n",
      "Epoch 41/50\n",
      "7002/7002 [==============================] - 47s - loss: 1.2684 - val_loss: 1.5086\n",
      "Epoch 42/50\n",
      "7002/7002 [==============================] - 47s - loss: 1.2502 - val_loss: 1.4535\n",
      "Epoch 43/50\n",
      "7002/7002 [==============================] - 47s - loss: 1.2358 - val_loss: 1.4352\n",
      "Epoch 44/50\n",
      "7002/7002 [==============================] - 47s - loss: 1.2255 - val_loss: 1.4196\n",
      "Epoch 45/50\n",
      "7002/7002 [==============================] - 47s - loss: 1.2219 - val_loss: 1.4473\n",
      "Epoch 46/50\n",
      "7002/7002 [==============================] - 47s - loss: 1.2133 - val_loss: 1.4697\n",
      "Epoch 47/50\n",
      "7002/7002 [==============================] - 47s - loss: 1.2076 - val_loss: 1.4377\n",
      "Epoch 48/50\n",
      "7002/7002 [==============================] - 47s - loss: 1.2182 - val_loss: 1.3809\n",
      "Epoch 49/50\n",
      "7002/7002 [==============================] - 47s - loss: 1.2099 - val_loss: 1.3658\n",
      "Epoch 50/50\n",
      "7002/7002 [==============================] - 47s - loss: 1.2007 - val_loss: 1.4025\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14ce8d7b8>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biternion_vgg_prob.fit(x=[xtr, log_kappa] , y=ytr_bit, batch_size=100, validation_split=0.1, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_kappa_te = np.ones([ytr_bit.shape[0], 1])*0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "yte_preds = bit2deg(biternion_vgg_prob.predict([xte, log_kappa_te])[:,0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = maad_from_deg(yte_preds, yte_deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.179481105679233"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
