{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Dense, Lambda, Flatten, Activation, Merge, Concatenate, Add\n",
    "from keras import layers\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Model, Sequential\n",
    "from keras.objectives import binary_crossentropy\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.models import load_model\n",
    "\n",
    "from models import vgg\n",
    "from models.cvae import CVAE\n",
    "from utils.angles import deg2bit, bit2deg\n",
    "from utils.losses import mad_loss_tf, cosine_loss_tf, von_mises_loss_tf, maad_from_deg\n",
    "from utils.losses import gaussian_kl_divergence_tf, gaussian_kl_divergence_np\n",
    "from utils.losses  import von_mises_log_likelihood_tf, von_mises_log_likelihood_np\n",
    "from utils.towncentre import load_towncentre\n",
    "from utils.experiements import get_experiment_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TownCentre data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtr, ytr_deg, xval, yval_deg, xte, yte_deg = load_towncentre('data/TownCentre.pkl.gz', canonical_split=True)\n",
    "image_height, image_width = xtr.shape[1], xtr.shape[2]\n",
    "ytr_bit = deg2bit(ytr_deg)\n",
    "yval_bit = deg2bit(yval_deg)\n",
    "yte_bit = deg2bit(yte_deg)\n",
    "\n",
    "image_height, image_width, n_channels = xtr.shape[1:]\n",
    "flatten_x_shape = xtr[0].flatten().shape[0]\n",
    "phi_shape = yte_bit.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "# fig, axs = plt.subplots(1, 10, figsize=(30, 15))\n",
    "# for i in range(0, 10):\n",
    "#     axs[i].imshow(xtr[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notation\n",
    "\n",
    "$x$ - image,\n",
    "\n",
    "$\\phi$ - head angle,\n",
    "\n",
    "$u$ - hidden variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prior network\n",
    "\n",
    "$ p(u|x) \\sim \\mathcal{N}(\\mu_1(x, \\theta), \\sigma_1(x, \\theta)) $\n",
    "\n",
    "#### Encoder network\n",
    "\n",
    "$ q(u|x,\\phi) \\sim \\mathcal{N}(\\mu_2(x, \\theta), \\sigma_2(x, \\theta)) $\n",
    "\n",
    "#### Sample  $u \\sim \\{p(u|x), q(u|x,\\phi) \\}$\n",
    "\n",
    "#### Decoder network\n",
    "\n",
    "$p(\\phi|u,x) \\sim \\mathcal{VM}(\\mu(x,u,\\theta''), \\kappa(x,u,\\theta'')) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_u = 8\n",
    "\n",
    "cvae_model = CVAE(n_hidden_units=n_u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from utils.custom_keras_callbacks import SideModelCheckpoint\n",
    "\n",
    "#proper logs format - 'logs/cvae.{epoch:02d}-{val_loss:.2f}.hdf5'\n",
    "\n",
    "# decoder_ckpt_path = 'logs/cvae.decoder.weights.hdf5'\n",
    "cvae_ckpt_path = 'logs/cvae.full_model.weights.hdf5'\n",
    "\n",
    "\n",
    "model_ckpt_callback = keras.callbacks.ModelCheckpoint(cvae_ckpt_path,\n",
    "                                                      monitor='val_loss',\n",
    "                                                      mode='min',\n",
    "                                                      save_best_only=True,\n",
    "                                                      save_weights_only=True,  \n",
    "                                                      verbose=1)\n",
    "\n",
    "# decoder_ckpt_callback = SideModelCheckpoint('cvae_decoder', \n",
    "#                                             model_to_save=cvae_model.decoder_model, \n",
    "#                                             save_path=decoder_ckpt_path,\n",
    "#                                             save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cvae_model.decoder_model.save_weights(decoder_ckpt_path)\n",
    "# cvae_model.full_model.save_weights(cvae_ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6882 samples, validate on 834 samples\n",
      "Epoch 1/50\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 1.5306Epoch 00000: val_loss improved from 1.57017 to 1.42602, saving model to logs/cvae.full_model.weights.hdf5\n",
      "6882/6882 [==============================] - 80s - loss: 1.5305 - val_loss: 1.4260\n",
      "Epoch 2/50\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 1.4921Epoch 00001: val_loss did not improve\n",
      "6882/6882 [==============================] - 79s - loss: 1.4921 - val_loss: 1.7035\n",
      "Epoch 3/50\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 1.4459Epoch 00002: val_loss improved from 1.42602 to 1.35367, saving model to logs/cvae.full_model.weights.hdf5\n",
      "6882/6882 [==============================] - 79s - loss: 1.4459 - val_loss: 1.3537\n",
      "Epoch 4/50\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 1.3480Epoch 00003: val_loss improved from 1.35367 to 1.25097, saving model to logs/cvae.full_model.weights.hdf5\n",
      "6882/6882 [==============================] - 79s - loss: 1.3479 - val_loss: 1.2510\n",
      "Epoch 5/50\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 1.2982Epoch 00004: val_loss did not improve\n",
      "6882/6882 [==============================] - 79s - loss: 1.2983 - val_loss: 1.7413\n",
      "Epoch 6/50\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 1.2631Epoch 00005: val_loss did not improve\n",
      "6882/6882 [==============================] - 79s - loss: 1.2632 - val_loss: 1.4897\n",
      "Epoch 7/50\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 1.2300Epoch 00006: val_loss did not improve\n",
      "6882/6882 [==============================] - 79s - loss: 1.2298 - val_loss: 1.4501\n",
      "Epoch 8/50\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 1.1902Epoch 00007: val_loss did not improve\n",
      "6882/6882 [==============================] - 79s - loss: 1.1901 - val_loss: 1.6399\n",
      "Epoch 9/50\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 1.1616Epoch 00008: val_loss did not improve\n",
      "6882/6882 [==============================] - 79s - loss: 1.1619 - val_loss: 1.7798\n",
      "Epoch 10/50\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 1.1004Epoch 00009: val_loss improved from 1.25097 to 1.10237, saving model to logs/cvae.full_model.weights.hdf5\n",
      "6882/6882 [==============================] - 79s - loss: 1.1001 - val_loss: 1.1024\n",
      "Epoch 11/50\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 1.0855Epoch 00010: val_loss improved from 1.10237 to 1.05007, saving model to logs/cvae.full_model.weights.hdf5\n",
      "6882/6882 [==============================] - 80s - loss: 1.0857 - val_loss: 1.0501\n",
      "Epoch 12/50\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 1.0151Epoch 00011: val_loss did not improve\n",
      "6882/6882 [==============================] - 78s - loss: 1.0152 - val_loss: 1.1444\n",
      "Epoch 13/50\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 0.9770Epoch 00012: val_loss did not improve\n",
      "6882/6882 [==============================] - 83s - loss: 0.9769 - val_loss: 1.1717\n",
      "Epoch 14/50\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 0.9361Epoch 00013: val_loss improved from 1.05007 to 0.98166, saving model to logs/cvae.full_model.weights.hdf5\n",
      "6882/6882 [==============================] - 89s - loss: 0.9361 - val_loss: 0.9817\n",
      "Epoch 15/50\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 0.9264Epoch 00014: val_loss did not improve\n",
      "6882/6882 [==============================] - 76s - loss: 0.9264 - val_loss: 1.1339\n",
      "Epoch 16/50\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 0.8646Epoch 00015: val_loss did not improve\n",
      "6882/6882 [==============================] - 79s - loss: 0.8646 - val_loss: 1.2224\n",
      "Epoch 17/50\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 0.8455Epoch 00016: val_loss improved from 0.98166 to 0.90345, saving model to logs/cvae.full_model.weights.hdf5\n",
      "6882/6882 [==============================] - 85s - loss: 0.8454 - val_loss: 0.9035\n",
      "Epoch 18/50\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 0.8176Epoch 00017: val_loss did not improve\n",
      "6882/6882 [==============================] - 96s - loss: 0.8183 - val_loss: 0.9552\n",
      "Epoch 19/50\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 0.7981Epoch 00018: val_loss did not improve\n",
      "6882/6882 [==============================] - 79s - loss: 0.7981 - val_loss: 0.9456\n",
      "Epoch 20/50\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 0.7441Epoch 00019: val_loss improved from 0.90345 to 0.87417, saving model to logs/cvae.full_model.weights.hdf5\n",
      "6882/6882 [==============================] - 100s - loss: 0.7449 - val_loss: 0.8742\n",
      "Epoch 21/50\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 0.7037Epoch 00020: val_loss improved from 0.87417 to 0.84083, saving model to logs/cvae.full_model.weights.hdf5\n",
      "6882/6882 [==============================] - 80s - loss: 0.7036 - val_loss: 0.8408\n",
      "Epoch 22/50\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 0.6849Epoch 00021: val_loss did not improve\n",
      "6882/6882 [==============================] - 80s - loss: 0.6852 - val_loss: 0.9254\n",
      "Epoch 23/50\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 0.6596Epoch 00022: val_loss did not improve\n",
      "6882/6882 [==============================] - 79s - loss: 0.6595 - val_loss: 0.9138\n",
      "Epoch 24/50\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 0.6814Epoch 00023: val_loss improved from 0.84083 to 0.82691, saving model to logs/cvae.full_model.weights.hdf5\n",
      "6882/6882 [==============================] - 80s - loss: 0.6812 - val_loss: 0.8269\n",
      "Epoch 25/50\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 0.6589Epoch 00024: val_loss did not improve\n",
      "6882/6882 [==============================] - 79s - loss: 0.6588 - val_loss: 0.9041\n",
      "Epoch 26/50\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 0.6483Epoch 00025: val_loss improved from 0.82691 to 0.79204, saving model to logs/cvae.full_model.weights.hdf5\n",
      "6882/6882 [==============================] - 79s - loss: 0.6484 - val_loss: 0.7920\n",
      "Epoch 27/50\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 0.6277Epoch 00026: val_loss did not improve\n",
      "6882/6882 [==============================] - 83s - loss: 0.6275 - val_loss: 1.9257\n",
      "Epoch 28/50\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 0.6493Epoch 00027: val_loss did not improve\n",
      "6882/6882 [==============================] - 79s - loss: 0.6494 - val_loss: 0.8418\n",
      "Epoch 29/50\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 0.5493Epoch 00028: val_loss improved from 0.79204 to 0.75471, saving model to logs/cvae.full_model.weights.hdf5\n",
      "6882/6882 [==============================] - 80s - loss: 0.5494 - val_loss: 0.7547\n",
      "Epoch 30/50\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 0.5107Epoch 00029: val_loss did not improve\n",
      "6882/6882 [==============================] - 80s - loss: 0.5123 - val_loss: 0.8512\n",
      "Epoch 31/50\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 0.5573Epoch 00030: val_loss improved from 0.75471 to 0.73163, saving model to logs/cvae.full_model.weights.hdf5\n",
      "6882/6882 [==============================] - 80s - loss: 0.5578 - val_loss: 0.7316\n",
      "Epoch 32/50\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 0.4744Epoch 00031: val_loss did not improve\n",
      "6882/6882 [==============================] - 79s - loss: 0.4745 - val_loss: 0.8081\n",
      "Epoch 33/50\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 0.4919Epoch 00032: val_loss did not improve\n",
      "6882/6882 [==============================] - 79s - loss: 0.4918 - val_loss: 0.8711\n",
      "Epoch 34/50\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 0.4745Epoch 00033: val_loss did not improve\n",
      "6882/6882 [==============================] - 80s - loss: 0.4749 - val_loss: 0.7526\n",
      "Epoch 35/50\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 0.4690Epoch 00034: val_loss did not improve\n",
      "6882/6882 [==============================] - 80s - loss: 0.4689 - val_loss: 0.7618\n",
      "Epoch 36/50\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 0.4316Epoch 00035: val_loss did not improve\n",
      "6882/6882 [==============================] - 79s - loss: 0.4316 - val_loss: 0.9162\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6880/6882 [============================>.] - ETA: 0s - loss: 0.4174Epoch 00036: val_loss improved from 0.73163 to 0.68820, saving model to logs/cvae.full_model.weights.hdf5\n",
      "6882/6882 [==============================] - 90s - loss: 0.4182 - val_loss: 0.6882\n",
      "Epoch 38/50\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 0.4066Epoch 00037: val_loss did not improve\n",
      "6882/6882 [==============================] - 98s - loss: 0.4064 - val_loss: 1.0043\n",
      "Epoch 39/50\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 0.3886Epoch 00038: val_loss did not improve\n",
      "6882/6882 [==============================] - 84s - loss: 0.3884 - val_loss: 1.0026\n",
      "Epoch 40/50\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 0.3553Epoch 00039: val_loss did not improve\n",
      "6882/6882 [==============================] - 79s - loss: 0.3552 - val_loss: 0.7497\n",
      "Epoch 41/50\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 0.4920Epoch 00040: val_loss did not improve\n",
      "6882/6882 [==============================] - 81s - loss: 0.4919 - val_loss: 0.7734\n",
      "Epoch 42/50\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 0.4114Epoch 00041: val_loss did not improve\n",
      "6882/6882 [==============================] - 80s - loss: 0.4113 - val_loss: 0.7843\n",
      "Epoch 43/50\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 0.3060Epoch 00042: val_loss improved from 0.68820 to 0.65123, saving model to logs/cvae.full_model.weights.hdf5\n",
      "6882/6882 [==============================] - 79s - loss: 0.3062 - val_loss: 0.6512\n",
      "Epoch 44/50\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 0.3077Epoch 00043: val_loss did not improve\n",
      "6882/6882 [==============================] - 80s - loss: 0.3078 - val_loss: 0.7284\n",
      "Epoch 45/50\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 0.2906Epoch 00044: val_loss did not improve\n",
      "6882/6882 [==============================] - 80s - loss: 0.2908 - val_loss: 0.7408\n",
      "Epoch 46/50\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 0.2597Epoch 00045: val_loss did not improve\n",
      "6882/6882 [==============================] - 80s - loss: 0.2597 - val_loss: 1.0577\n",
      "Epoch 47/50\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 0.2481Epoch 00046: val_loss did not improve\n",
      "6882/6882 [==============================] - 80s - loss: 0.2482 - val_loss: 0.7762\n",
      "Epoch 48/50\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 0.1985Epoch 00047: val_loss did not improve\n",
      "6882/6882 [==============================] - 80s - loss: 0.1986 - val_loss: 0.7104\n",
      "Epoch 49/50\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 0.2240Epoch 00048: val_loss did not improve\n",
      "6882/6882 [==============================] - 76s - loss: 0.2239 - val_loss: 0.7111\n",
      "Epoch 50/50\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 0.2001Epoch 00049: val_loss did not improve\n",
      "6882/6882 [==============================] - 99s - loss: 0.2001 - val_loss: 0.7407\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x141e86b38>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvae_model.full_model.fit([xtr, ytr_bit], [ytr_bit], batch_size=10, epochs=50, validation_data=([xval, yval_bit], yval_bit),\n",
    "                   callbacks=[model_ckpt_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions using decoder part\n",
    "\n",
    "$ \\phi_i = \\mu(x_i,u_i,\\theta'') $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvae_best = CVAE(n_hidden_units=n_u)\n",
    "cvae_best.full_model.load_weights(cvae_ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import sem\n",
    "\n",
    "def _eval_model(cvae_model, x, ytrue_deg, ytrue_bit, data_part):\n",
    "    \n",
    "    n_samples = x.shape[0]\n",
    "\n",
    "    cvae_preds = cvae_model.full_model.predict([x, ytrue_bit])\n",
    "    elbo_te, ll_te, kl_te = cvae_model._cvae_elbo_loss_np(ytrue_bit, cvae_preds)\n",
    "\n",
    "    ypreds = cvae_model.decoder_model.predict(x)\n",
    "    ypreds_bit = ypreds[:,0:2]\n",
    "    kappa_preds_te = ypreds[:,2:]\n",
    "\n",
    "    ypreds_deg = bit2deg(ypreds_bit)\n",
    "\n",
    "    loss_te = maad_from_deg(ytrue_deg, ypreds_deg)\n",
    "    mean_loss_te = np.mean(loss_te)\n",
    "    std_loss_te = np.std(loss_te)\n",
    "\n",
    "    print(\"MAAD error (test) : %f ± %f\" % (mean_loss_te, std_loss_te))\n",
    "\n",
    "    print(\"kappa (test) : %f ± %f\" % (np.mean(kappa_preds_te), np.std(kappa_preds_te)))\n",
    "\n",
    "    log_likelihood_loss = von_mises_log_likelihood_np(ytrue_bit, ypreds_bit, kappa_preds_te,\n",
    "                                                         input_type='biternion')\n",
    "\n",
    "    print(\"ELBO (%s) : %f ± %f SEM\" % (data_part, np.mean(-elbo_te), sem(-elbo_te)))\n",
    "\n",
    "    print(\"KL(encoder|prior) (%s) : %f ± %f SEM\" % (data_part, np.mean(-kl_te), sem(-kl_te)))\n",
    "\n",
    "    print(\"log-likelihood (%s) : %f±%fSEM\" % (data_part, \n",
    "                                              np.mean(log_likelihood_loss), \n",
    "                                              sem(log_likelihood_loss)))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAAD error (test) : 54.725613 ± 48.245662\n",
      "kappa (test) : 0.934393 ± 0.810261\n",
      "ELBO (train) : -1.568528 ± 0.006742 SEM\n",
      "KL(encoder|prior) (train) : -0.035083 ± 0.000357 SEM\n",
      "log-likelihood (train) : -1.543154±0.006767SEM\n"
     ]
    }
   ],
   "source": [
    "_eval_model(cvae_best, xtr, ytr_deg, ytr_bit, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAAD error (test) : 53.554670 ± 47.014745\n",
      "kappa (test) : 0.943233 ± 0.826707\n",
      "ELBO (validation) : -1.570017 ± 0.018833 SEM\n",
      "KL(encoder|prior) (validation) : -0.037350 ± 0.001082 SEM\n",
      "log-likelihood (validation) : -1.539291±0.019358SEM\n"
     ]
    }
   ],
   "source": [
    "_eval_model(cvae_best, xval, yval_deg, yval_bit, 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAAD error (test) : 47.863967 ± 45.116663\n",
      "kappa (test) : 0.903833 ± 0.801953\n",
      "ELBO (test) : -1.519896 ± 0.017887 SEM\n",
      "KL(encoder|prior) (test) : -0.034243 ± 0.000985 SEM\n",
      "log-likelihood (test) : -1.485811±0.017619SEM\n"
     ]
    }
   ],
   "source": [
    "_eval_model(cvae_best, xte, yte_deg, yte_bit, 'test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
