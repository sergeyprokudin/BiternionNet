{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Lambda, Flatten, Activation, Merge, Concatenate, Add\n",
    "from keras import layers\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Model, Sequential\n",
    "from keras.objectives import binary_crossentropy\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "from models import vgg\n",
    "from utils.angles import deg2bit, bit2deg\n",
    "from utils.losses import mad_loss_tf, cosine_loss_tf, von_mises_loss_tf, maad_from_deg\n",
    "from utils.losses import gaussian_kl_divergence_tf, gaussian_kl_divergence_np\n",
    "from utils.losses  import von_mises_log_likelihood_tf, von_mises_log_likelihood_np\n",
    "from utils.towncentre import load_towncentre\n",
    "from utils.experiements import get_experiment_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TownCentre data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtr, ytr_deg, xte, yte_deg = load_towncentre('data/TownCentre.pkl.gz', canonical_split=True)\n",
    "image_height, image_width = xtr.shape[1], xtr.shape[2]\n",
    "ytr_bit = deg2bit(ytr_deg)\n",
    "yte_bit = deg2bit(yte_deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(1, 10, figsize=(30, 15))\n",
    "# for i in range(0, 10):\n",
    "#     axs[i].imshow(xtr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_height, image_width, n_channels = xtr.shape[1:]\n",
    "flatten_x_shape = xtr[0].flatten().shape[0]\n",
    "phi_shape = yte_bit.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notation\n",
    "\n",
    "$x$ - image,\n",
    "\n",
    "$\\phi$ - head angle,\n",
    "\n",
    "$u$ - hidden variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prior network\n",
    "\n",
    "$ p(u|x) \\sim \\mathcal{N}(\\mu_1(x, \\theta), \\sigma_1(x, \\theta)) $\n",
    "\n",
    "#### Encoder network\n",
    "\n",
    "$ q(u|x,\\phi) \\sim \\mathcal{N}(\\mu_2(x, \\theta), \\sigma_2(x, \\theta)) $\n",
    "\n",
    "#### Sample  $u \\sim \\{p(u|x), q(u|x,\\phi) \\}$\n",
    "\n",
    "#### Decoder network\n",
    "\n",
    "$p(\\phi|u,x) \\sim \\mathcal{VM}(\\mu(x,u,\\theta''), \\kappa(x,u,\\theta'')) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CVAE:\n",
    "\n",
    "    def __init__(self,\n",
    "                 image_height=50,\n",
    "                 image_width=50,\n",
    "                 n_channels=3,\n",
    "                 n_hidden_units=8):\n",
    "\n",
    "        self.n_u = n_hidden_units\n",
    "        self.image_height = image_height\n",
    "        self.image_width = image_width\n",
    "        self.n_channels = n_channels\n",
    "        self.phi_shape = 2\n",
    "\n",
    "        self.x = Input(shape=[self.image_height, self.image_width, self.n_channels])\n",
    "        self.phi = Input(shape=[self.phi_shape])\n",
    "        self.u = Input(shape=[self.n_u])\n",
    "\n",
    "        self.x_vgg = vgg.vgg_model(image_height=self.image_height,\n",
    "                                   image_width=self.image_width)(self.x)\n",
    "\n",
    "        self.x_vgg_shape = self.x_vgg.get_shape().as_list()[1]\n",
    "\n",
    "        self.mu_encoder, self.log_sigma_encoder = self._encoder_mu_log_sigma()\n",
    "        \n",
    "        self.mu_prior, self.log_sigma_prior = self._prior_mu_log_sigma()\n",
    "        \n",
    "        self.u_prior = Lambda(self._sample_u)([self.mu_prior, self.log_sigma_prior])\n",
    "        self.u_encoder = Lambda(self._sample_u)([self.mu_encoder, self.log_sigma_encoder])\n",
    "\n",
    "        self.x_vgg_u = concatenate([self.x_vgg, self.u_encoder])\n",
    "\n",
    "        self.decoder_mu_seq, self.decoder_kappa_seq = self._decoder_net_seq()\n",
    "\n",
    "        self.full_model = Model(inputs=[self.x, self.phi],\n",
    "                                outputs=concatenate([self.mu_prior,\n",
    "                                                     self.log_sigma_prior,\n",
    "                                                     self.mu_encoder,\n",
    "                                                     self.log_sigma_encoder,\n",
    "                                                     self.decoder_mu_seq(self.x_vgg_u),\n",
    "                                                     self.decoder_kappa_seq(self.x_vgg_u)]))\n",
    "        \n",
    "        self.decoder_input = concatenate([self.x_vgg, self.u_prior])\n",
    "        self.decoder_model = Model(inputs=[self.x],\n",
    "                                   outputs=concatenate([self.decoder_mu_seq(self.decoder_input),\n",
    "                                                        self.decoder_kappa_seq(self.decoder_input)]))\n",
    "        \n",
    "    def _encoder_mu_log_sigma(self):\n",
    "\n",
    "        x_vgg_phi = concatenate([self.x_vgg, self.phi])\n",
    "\n",
    "        hidden = Dense(512, activation='relu')(x_vgg_phi)\n",
    "\n",
    "        mu_encoder = Dense(self.n_u, activation='linear')(hidden)\n",
    "        log_sigma_encoder = Dense(self.n_u, activation='linear')(hidden)\n",
    "\n",
    "        return mu_encoder, log_sigma_encoder\n",
    "\n",
    "    def _prior_mu_log_sigma(self):\n",
    "\n",
    "        hidden = Dense(512, activation='relu')(self.x_vgg)\n",
    "\n",
    "        mu_prior = Dense(self.n_u, activation='linear')(hidden)\n",
    "        log_sigma_prior = Dense(self.n_u, activation='linear')(hidden)\n",
    "\n",
    "        return mu_prior, log_sigma_prior\n",
    "    \n",
    "    def _sample_u(self, args):\n",
    "        mu, log_sigma = args\n",
    "        eps = K.random_normal(shape=[self.n_u], mean=0., stddev=1.)\n",
    "        return mu + K.exp(log_sigma / 2) * eps\n",
    "\n",
    "    def _decoder_net_seq(self):\n",
    "        decoder_mu = Sequential()\n",
    "        decoder_mu.add(Dense(512, activation='relu',input_shape=[self.x_vgg_shape + self.n_u]))\n",
    "        # decoder_mu.add(Dense(512, activation='relu'))\n",
    "        decoder_mu.add(Dense(2, activation='linear'))\n",
    "        decoder_mu.add(Lambda(lambda x: K.l2_normalize(x, axis=1)))\n",
    "\n",
    "        decoder_kappa = Sequential()\n",
    "        decoder_kappa.add(Dense(512, activation='relu', input_shape=[self.x_vgg_shape + self.n_u]))\n",
    "        # decoder_kappa.add(Dense(512, activation='relu'))\n",
    "        decoder_kappa.add(Dense(1, activation='linear'))\n",
    "        decoder_kappa.add(Lambda(lambda x: K.abs(x)))\n",
    "        \n",
    "        return decoder_mu, decoder_kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_u = 8\n",
    "\n",
    "cvae = CVAE(n_hidden_units=n_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cvae_loss(y_true, model_output):\n",
    "    mu_prior = model_output[:, 0:n_u]\n",
    "    log_sigma_prior = model_output[:, n_u:n_u*2]\n",
    "    mu_encoder = model_output[:, n_u*2:n_u*3]\n",
    "    log_sigma_encoder = model_output[:, n_u*3:n_u*4]\n",
    "    mu_pred = model_output[:, n_u*4:n_u*4+2]\n",
    "    kappa_pred = model_output[:, n_u*4+2:]\n",
    "    log_likelihood = von_mises_log_likelihood_tf(y_true, mu_pred, kappa_pred, input_type='biternion')\n",
    "    kl = gaussian_kl_divergence_tf(mu_encoder, log_sigma_encoder, mu_prior, log_sigma_prior)\n",
    "    return K.mean(-log_likelihood + kl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cvae_elbo_np(y_true, y_pred):\n",
    "    mu_prior = y_pred[:, 0:n_u]\n",
    "    log_sigma_prior = y_pred[:, n_u:n_u*2]\n",
    "    mu_encoder = y_pred[:, n_u*2:n_u*3]\n",
    "    log_sigma_encoder = y_pred[:, n_u*3:n_u*4]\n",
    "    mu_pred = y_pred[:, n_u*4:n_u*4+2]\n",
    "    kappa_pred = y_pred[:, n_u*4+2:]\n",
    "    log_likelihood = von_mises_log_likelihood_np(y_true, mu_pred, kappa_pred, input_type='biternion')\n",
    "    kl = gaussian_kl_divergence_np(mu_encoder, log_sigma_encoder, mu_prior, log_sigma_prior)\n",
    "    loss = -log_likelihood + kl\n",
    "    return loss, log_likelihood, kl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvae = CVAE()\n",
    "#optimizer = keras.optimizers.Adadelta(lr=0.001)\n",
    "cvae.full_model.compile(optimizer='adam', loss=cvae_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "model_ckpt_callback = keras.callbacks.ModelCheckpoint('cvae_full.h5',\n",
    "                                                      monitor='val_loss',\n",
    "                                                      mode='min',\n",
    "                                                      save_best_only=True,\n",
    "                                                      verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7002 samples, validate on 778 samples\n",
      "Epoch 1/20\n",
      "7000/7002 [============================>.] - ETA: 0s - loss: 1.8633Epoch 00000: val_loss improved from inf to 1.70946, saving model to cvae_full.h5\n",
      "7002/7002 [==============================] - 102s - loss: 1.8634 - val_loss: 1.7095\n",
      "Epoch 2/20\n",
      " 670/7002 [=>............................] - ETA: 89s - loss: 1.5444"
     ]
    }
   ],
   "source": [
    "cvae.full_model.fit([xtr, ytr_bit], [ytr_bit], batch_size=10, epochs=20, validation_split=0.1,\n",
    "                   callbacks=[model_ckpt_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions using decoder part\n",
    "\n",
    "$ \\phi_i = \\mu(x_i,u_i,\\theta'') $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import sem\n",
    "\n",
    "n_samples = xte.shape[0]\n",
    "#ute = np.random.normal(0,1, [n_samples,n_u])\n",
    "\n",
    "#yte_cvae_preds = cvae.full_model.predict([xte, yte_bit])\n",
    "\n",
    "cvae_preds = cvae.full_model.predict([xte, yte_bit])\n",
    "elbo_te, ll_te, kl_te = cvae_elbo_np(yte_bit, cvae_preds)\n",
    "\n",
    "yte_preds = cvae.decoder_model.predict(xte)\n",
    "yte_preds_bit = yte_preds[:,0:2]\n",
    "kappa_preds_te = yte_preds[:,2:]\n",
    "\n",
    "yte_preds_deg = bit2deg(yte_preds_bit)\n",
    "\n",
    "loss_te = maad_from_deg(yte_preds_deg, yte_deg)\n",
    "mean_loss_te = np.mean(loss_te)\n",
    "std_loss_te = np.std(loss_te)\n",
    "\n",
    "print(\"MAAD error (test) : %f ± %f\" % (mean_loss_te, std_loss_te))\n",
    "\n",
    "#kappa_preds_te = np.ones([xte.shape[0], 1]) \n",
    "\n",
    "print(\"kappa (test) : %f ± %f\" % (np.mean(kappa_preds_te), np.std(kappa_preds_te)))\n",
    "\n",
    "log_likelihood_loss_te = von_mises_log_likelihood_np(yte_bit, yte_preds_bit, kappa_preds_te,\n",
    "                                                     input_type='biternion')\n",
    "\n",
    "\n",
    "print(\"ELBO (test) : %f ± %f SEM\" % (np.mean(-elbo_te), sem(-elbo_te)))\n",
    "# print(\"log-likelihood (test) : %f ± %f SEM\" % (np.mean(-ll_te), sem(-ll_te)))\n",
    "print(\"KL(encoder|prior) (test) : %f ± %f SEM\" % (np.mean(-kl_te), sem(-kl_te)))\n",
    "\n",
    "print(\"log-likelihood (test) : %f±%fSEM\" % (np.mean(log_likelihood_loss_te), sem(log_likelihood_loss_te)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = xtr.shape[0]\n",
    "#utr = np.random.normal(0,1, [n_samples,n_u])\n",
    "\n",
    "#ytr_cvae_preds = cvae.full_model.predict([xtr, ytr_bit])\n",
    "\n",
    "cvae_preds = cvae.full_model.predict([xtr, ytr_bit])\n",
    "elbo_tr, ll_tr, kl_tr = cvae_elbo_np(ytr_bit, cvae_preds)\n",
    "\n",
    "ytr_preds = cvae.decoder_model.predict(xtr)\n",
    "ytr_preds_bit = ytr_preds[:,0:2]\n",
    "kappa_preds_tr = ytr_preds[:,2:]\n",
    "\n",
    "ytr_preds_deg = bit2deg(ytr_preds_bit)\n",
    "\n",
    "loss_tr = maad_from_deg(ytr_preds_deg, ytr_deg)\n",
    "mean_loss_tr = np.mean(loss_tr)\n",
    "std_loss_tr = np.std(loss_tr)\n",
    "\n",
    "print(\"MAAD error (train) : %f ± %f\" % (mean_loss_tr, std_loss_tr))\n",
    "\n",
    "#kappa_preds_tr = np.ones([xtr.shape[0], 1]) \n",
    "\n",
    "print(\"kappa (train) : %f ± %f\" % (np.mean(kappa_preds_tr), np.std(kappa_preds_tr)))\n",
    "\n",
    "log_likelihood_loss_tr = von_mises_log_likelihood_np(ytr_bit, ytr_preds_bit, kappa_preds_tr,\n",
    "                                                     input_type='biternion')\n",
    "\n",
    "\n",
    "\n",
    "print(\"ELBO (train) : %f ± %f SEM\" % (np.mean(-elbo_tr), sem(-elbo_tr)))\n",
    "# print(\"log-likelihood (train) : %f ± %f SEM\" % (np.mean(-ll_tr), sem(-ll_tr)))\n",
    "print(\"KL(encoder|prior) (train) : %f ± %f SEM\" % (np.mean(-kl_tr), sem(-kl_tr)))\n",
    "\n",
    "print(\"log-likelihood (train) : %f±%fSEM\" % (np.mean(log_likelihood_loss_tr), sem(log_likelihood_loss_tr)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
