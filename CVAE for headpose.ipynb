{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Lambda, Flatten, Activation, Merge, Concatenate, Add\n",
    "from keras import layers\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Model, Sequential\n",
    "from keras.objectives import binary_crossentropy\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "from models import vgg\n",
    "from models.cvae import CVAE\n",
    "from utils.angles import deg2bit, bit2deg\n",
    "from utils.losses import mad_loss_tf, cosine_loss_tf, von_mises_loss_tf, maad_from_deg\n",
    "from utils.losses import gaussian_kl_divergence_tf, gaussian_kl_divergence_np\n",
    "from utils.losses  import von_mises_log_likelihood_tf, von_mises_log_likelihood_np\n",
    "from utils.towncentre import load_towncentre\n",
    "from utils.experiements import get_experiment_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TownCentre data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtr, ytr_deg, xval, yval_deg, xte, yte_deg = load_towncentre('data/TownCentre.pkl.gz', canonical_split=True)\n",
    "image_height, image_width = xtr.shape[1], xtr.shape[2]\n",
    "ytr_bit = deg2bit(ytr_deg)\n",
    "yval_bit = deg2bit(yval_deg)\n",
    "yte_bit = deg2bit(yte_deg)\n",
    "\n",
    "image_height, image_width, n_channels = xtr.shape[1:]\n",
    "flatten_x_shape = xtr[0].flatten().shape[0]\n",
    "phi_shape = yte_bit.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "# fig, axs = plt.subplots(1, 10, figsize=(30, 15))\n",
    "# for i in range(0, 10):\n",
    "#     axs[i].imshow(xtr[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notation\n",
    "\n",
    "$x$ - image,\n",
    "\n",
    "$\\phi$ - head angle,\n",
    "\n",
    "$u$ - hidden variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prior network\n",
    "\n",
    "$ p(u|x) \\sim \\mathcal{N}(\\mu_1(x, \\theta), \\sigma_1(x, \\theta)) $\n",
    "\n",
    "#### Encoder network\n",
    "\n",
    "$ q(u|x,\\phi) \\sim \\mathcal{N}(\\mu_2(x, \\theta), \\sigma_2(x, \\theta)) $\n",
    "\n",
    "#### Sample  $u \\sim \\{p(u|x), q(u|x,\\phi) \\}$\n",
    "\n",
    "#### Decoder network\n",
    "\n",
    "$p(\\phi|u,x) \\sim \\mathcal{VM}(\\mu(x,u,\\theta''), \\kappa(x,u,\\theta'')) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_u = 8\n",
    "\n",
    "cvae = CVAE(n_hidden_units=n_u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from utils.custom_keras_callbacks import SideModelCheckpoint\n",
    "\n",
    "#proper logs format - 'logs/cvae.{epoch:02d}-{val_loss:.2f}.hdf5'\n",
    "\n",
    "model_ckpt_callback = keras.callbacks.ModelCheckpoint('logs/cvae.full.best.hdf5',\n",
    "                                                      monitor='val_loss',\n",
    "                                                      mode='min',\n",
    "                                                      save_best_only=True,\n",
    "                                                      verbose=1)\n",
    "\n",
    "save_decoder_callback = SideModelCheckpoint('cvae_decoder', model_to_save=cvae.decoder_model, save_path='logs/cvae_decoder.{epoch:02d}-{val_loss:.2f}.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6882 samples, validate on 834 samples\n",
      "Epoch 1/20\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 1.6971Epoch 00000: val_loss improved from inf to 1.37882, saving model to logs/cvae.00-1.38.hdf5\n",
      "val_loss improved from inf to 1.378820, saving cvae_decoder to logs/cvae_decoder.01-1.38.hdf5\n",
      "6882/6882 [==============================] - 80s - loss: 1.6970 - val_loss: 1.3788\n",
      "Epoch 2/20\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 1.4794Epoch 00001: val_loss improved from 1.37882 to 1.32081, saving model to logs/cvae.01-1.32.hdf5\n",
      "val_loss improved from 1.378820 to 1.320809, saving cvae_decoder to logs/cvae_decoder.02-1.32.hdf5\n",
      "6882/6882 [==============================] - 79s - loss: 1.4793 - val_loss: 1.3208\n",
      "Epoch 3/20\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 1.3934Epoch 00002: val_loss improved from 1.32081 to 1.29021, saving model to logs/cvae.02-1.29.hdf5\n",
      "val_loss improved from 1.320809 to 1.290211, saving cvae_decoder to logs/cvae_decoder.03-1.29.hdf5\n",
      "6882/6882 [==============================] - 79s - loss: 1.3931 - val_loss: 1.2902\n",
      "Epoch 4/20\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 1.3503Epoch 00003: val_loss did not improve\n",
      "6882/6882 [==============================] - 79s - loss: 1.3511 - val_loss: 2.1734\n",
      "Epoch 5/20\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 1.3586Epoch 00004: val_loss did not improve\n",
      "6882/6882 [==============================] - 79s - loss: 1.3585 - val_loss: 2.0640\n",
      "Epoch 6/20\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 1.2495Epoch 00005: val_loss improved from 1.29021 to 1.27215, saving model to logs/cvae.05-1.27.hdf5\n",
      "val_loss improved from 1.290211 to 1.272154, saving cvae_decoder to logs/cvae_decoder.06-1.27.hdf5\n",
      "6882/6882 [==============================] - 79s - loss: 1.2495 - val_loss: 1.2722\n",
      "Epoch 7/20\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 1.2308Epoch 00006: val_loss did not improve\n",
      "6882/6882 [==============================] - 79s - loss: 1.2313 - val_loss: 1.4014\n",
      "Epoch 8/20\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 1.2375Epoch 00007: val_loss did not improve\n",
      "6882/6882 [==============================] - 91s - loss: 1.2372 - val_loss: 2.2595\n",
      "Epoch 9/20\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 1.1725Epoch 00008: val_loss did not improve\n",
      "6882/6882 [==============================] - 88s - loss: 1.1723 - val_loss: 1.2885\n",
      "Epoch 10/20\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 1.1053Epoch 00009: val_loss improved from 1.27215 to 1.13432, saving model to logs/cvae.09-1.13.hdf5\n",
      "val_loss improved from 1.272154 to 1.134317, saving cvae_decoder to logs/cvae_decoder.10-1.13.hdf5\n",
      "6882/6882 [==============================] - 79s - loss: 1.1053 - val_loss: 1.1343\n",
      "Epoch 11/20\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 1.0975Epoch 00010: val_loss did not improve\n",
      "6882/6882 [==============================] - 80s - loss: 1.0976 - val_loss: 1.2585\n",
      "Epoch 12/20\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 1.0845Epoch 00011: val_loss did not improve\n",
      "6882/6882 [==============================] - 79s - loss: 1.0844 - val_loss: 1.7341\n",
      "Epoch 13/20\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 1.0252Epoch 00012: val_loss did not improve\n",
      "6882/6882 [==============================] - 79s - loss: 1.0251 - val_loss: 1.7249\n",
      "Epoch 14/20\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 0.9889Epoch 00013: val_loss did not improve\n",
      "6882/6882 [==============================] - 79s - loss: 0.9888 - val_loss: 1.3874\n",
      "Epoch 15/20\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 0.9398Epoch 00014: val_loss improved from 1.13432 to 1.00317, saving model to logs/cvae.14-1.00.hdf5\n",
      "val_loss improved from 1.134317 to 1.003174, saving cvae_decoder to logs/cvae_decoder.15-1.00.hdf5\n",
      "6882/6882 [==============================] - 80s - loss: 0.9399 - val_loss: 1.0032\n",
      "Epoch 16/20\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 0.8897Epoch 00015: val_loss improved from 1.00317 to 0.87619, saving model to logs/cvae.15-0.88.hdf5\n",
      "val_loss improved from 1.003174 to 0.876189, saving cvae_decoder to logs/cvae_decoder.16-0.88.hdf5\n",
      "6882/6882 [==============================] - 80s - loss: 0.8895 - val_loss: 0.8762\n",
      "Epoch 17/20\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 0.8674Epoch 00016: val_loss did not improve\n",
      "6882/6882 [==============================] - 80s - loss: 0.8677 - val_loss: 1.0768\n",
      "Epoch 18/20\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 0.8378Epoch 00017: val_loss did not improve\n",
      "6882/6882 [==============================] - 79s - loss: 0.8378 - val_loss: 0.9057\n",
      "Epoch 19/20\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 0.8418Epoch 00018: val_loss improved from 0.87619 to 0.87176, saving model to logs/cvae.18-0.87.hdf5\n",
      "val_loss improved from 0.876189 to 0.871762, saving cvae_decoder to logs/cvae_decoder.19-0.87.hdf5\n",
      "6882/6882 [==============================] - 80s - loss: 0.8419 - val_loss: 0.8718\n",
      "Epoch 20/20\n",
      "6880/6882 [============================>.] - ETA: 0s - loss: 0.7887Epoch 00019: val_loss did not improve\n",
      "6882/6882 [==============================] - 80s - loss: 0.7887 - val_loss: 0.8747\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x142e19b00>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvae.full_model.fit([xtr, ytr_bit], [ytr_bit], batch_size=10, epochs=20, validation_data=([xval, yval_bit], yval_bit),\n",
    "                   callbacks=[model_ckpt_callback, save_decoder_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions using decoder part\n",
    "\n",
    "$ \\phi_i = \\mu(x_i,u_i,\\theta'') $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import sem\n",
    "\n",
    "def _eval_model(x, ytrue_deg, ytrue_bit, data_part):\n",
    "    \n",
    "    n_samples = x.shape[0]\n",
    "\n",
    "    cvae_preds = cvae.full_model.predict([x, ytrue_bit])\n",
    "    elbo_te, ll_te, kl_te = cvae._cvae_elbo_loss_np(ytrue_bit, cvae_preds)\n",
    "\n",
    "    ypreds = cvae.decoder_model.predict(x)\n",
    "    ypreds_bit = ypreds[:,0:2]\n",
    "    kappa_preds_te = ypreds[:,2:]\n",
    "\n",
    "    ypreds_deg = bit2deg(ypreds_bit)\n",
    "\n",
    "    loss_te = maad_from_deg(ytrue_deg, ypreds_deg)\n",
    "    mean_loss_te = np.mean(loss_te)\n",
    "    std_loss_te = np.std(loss_te)\n",
    "\n",
    "    print(\"MAAD error (test) : %f ± %f\" % (mean_loss_te, std_loss_te))\n",
    "\n",
    "    print(\"kappa (test) : %f ± %f\" % (np.mean(kappa_preds_te), np.std(kappa_preds_te)))\n",
    "\n",
    "    log_likelihood_loss = von_mises_log_likelihood_np(ytrue_bit, ypreds_bit, kappa_preds_te,\n",
    "                                                         input_type='biternion')\n",
    "\n",
    "    print(\"ELBO (%s) : %f ± %f SEM\" % (data_part, np.mean(-elbo_te), sem(-elbo_te)))\n",
    "\n",
    "    print(\"KL(encoder|prior) (%s) : %f ± %f SEM\" % (data_part, np.mean(-kl_te), sem(-kl_te)))\n",
    "\n",
    "    print(\"log-likelihood (%s) : %f±%fSEM\" % (data_part, \n",
    "                                              np.mean(log_likelihood_loss), \n",
    "                                              sem(log_likelihood_loss)))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAAD error (test) : 25.215531 ± 30.991783\n",
      "kappa (test) : 3.314029 ± 2.315937\n",
      "ELBO (train) : -0.811803 ± 0.008588 SEM\n",
      "KL(encoder|prior) (train) : -0.000351 ± 0.000020 SEM\n",
      "log-likelihood (train) : -0.811844±0.008640SEM\n"
     ]
    }
   ],
   "source": [
    "_eval_model(xtr, ytr_deg, ytr_bit, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAAD error (test) : 28.117048 ± 34.208823\n",
      "kappa (test) : 3.372568 ± 2.345989\n",
      "ELBO (test) : -0.874091 ± 0.026384 SEM\n",
      "KL(encoder|prior) (test) : -0.000409 ± 0.000051 SEM\n",
      "log-likelihood (test) : -0.880891±0.026426SEM\n"
     ]
    }
   ],
   "source": [
    "_eval_model(xte, yte_deg, yte_bit, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAAD error (test) : 29.101876 ± 36.751117\n",
      "kappa (test) : 3.480289 ± 2.587593\n",
      "ELBO (validation) : -0.870957 ± 0.028748 SEM\n",
      "KL(encoder|prior) (validation) : -0.000533 ± 0.000080 SEM\n",
      "log-likelihood (validation) : -0.868463±0.028687SEM\n"
     ]
    }
   ],
   "source": [
    "_eval_model(xval, yval_deg, yval_bit, 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAAD error (train) : 25.152544 ± 30.959030\n",
      "kappa (train) : 3.319907 ± 2.308599\n",
      "ELBO (train) : -0.812803 ± 0.008613 SEM\n",
      "KL(encoder|prior) (train) : -0.000351 ± 0.000020 SEM\n",
      "log-likelihood (train) : -0.811344±0.008667SEM\n"
     ]
    }
   ],
   "source": [
    "n_samples = xtr.shape[0]\n",
    "#utr = np.random.normal(0,1, [n_samples,n_u])\n",
    "\n",
    "#ytr_cvae_preds = cvae.full_model.predict([xtr, ytr_bit])\n",
    "\n",
    "cvae_preds = cvae.full_model.predict([xtr, ytr_bit])\n",
    "elbo_tr, ll_tr, kl_tr = cvae._cvae_elbo_loss_np(ytr_bit, cvae_preds)\n",
    "\n",
    "ytr_preds = cvae.decoder_model.predict(xtr)\n",
    "ytr_preds_bit = ytr_preds[:,0:2]\n",
    "kappa_preds_tr = ytr_preds[:,2:]\n",
    "\n",
    "ytr_preds_deg = bit2deg(ytr_preds_bit)\n",
    "\n",
    "loss_tr = maad_from_deg(ytr_preds_deg, ytr_deg)\n",
    "mean_loss_tr = np.mean(loss_tr)\n",
    "std_loss_tr = np.std(loss_tr)\n",
    "\n",
    "print(\"MAAD error (train) : %f ± %f\" % (mean_loss_tr, std_loss_tr))\n",
    "\n",
    "#kappa_preds_tr = np.ones([xtr.shape[0], 1]) \n",
    "\n",
    "print(\"kappa (train) : %f ± %f\" % (np.mean(kappa_preds_tr), np.std(kappa_preds_tr)))\n",
    "\n",
    "log_likelihood_loss_tr = von_mises_log_likelihood_np(ytr_bit, ytr_preds_bit, kappa_preds_tr,\n",
    "                                                     input_type='biternion')\n",
    "\n",
    "\n",
    "\n",
    "print(\"ELBO (train) : %f ± %f SEM\" % (np.mean(-elbo_tr), sem(-elbo_tr)))\n",
    "# print(\"log-likelihood (train) : %f ± %f SEM\" % (np.mean(-ll_tr), sem(-ll_tr)))\n",
    "print(\"KL(encoder|prior) (train) : %f ± %f SEM\" % (np.mean(-kl_tr), sem(-kl_tr)))\n",
    "\n",
    "print(\"log-likelihood (train) : %f±%fSEM\" % (np.mean(log_likelihood_loss_tr), sem(log_likelihood_loss_tr)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
