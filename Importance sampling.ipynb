{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Lambda, Flatten, Activation, Merge, Concatenate, Add\n",
    "from keras import layers\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Model, Sequential\n",
    "from keras.objectives import binary_crossentropy\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import sem\n",
    "from scipy.spatial.distance import squareform, pdist\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "\n",
    "from models import vgg\n",
    "from models.cvae import CVAE\n",
    "from models.cvae_mod import CVAE as CVAE_mod\n",
    "from utils.losses import von_mises_log_likelihood_np\n",
    "from utils.angles import deg2bit, bit2deg\n",
    "from utils.losses import mad_loss_tf, cosine_loss_tf, von_mises_loss_tf, maad_from_deg\n",
    "from utils.losses import gaussian_kl_divergence_tf, gaussian_kl_divergence_np\n",
    "from utils.losses import gaussian_log_likelihood_np, gaussian_log_likelihood_scipy, gaussian_log_likelihood_tf\n",
    "from utils.losses  import von_mises_log_likelihood_tf, von_mises_log_likelihood_np\n",
    "from utils.sampling import sample_multiple_gauassians_np\n",
    "from utils.towncentre import load_towncentre\n",
    "from utils.experiements import get_experiment_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train samples: 6916\n",
      "Number of validation samples: 874\n",
      "Number of test samples: 904\n"
     ]
    }
   ],
   "source": [
    "xtr, ytr_deg, xval, yval_deg, xte, yte_deg = load_towncentre('data/TownCentre.pkl.gz', canonical_split=True, verbose=1)\n",
    "\n",
    "image_height, image_width = xtr.shape[1], xtr.shape[2]\n",
    "ytr_bit = deg2bit(ytr_deg)\n",
    "yval_bit = deg2bit(yval_deg)\n",
    "yte_bit = deg2bit(yte_deg)\n",
    "yte_rad = np.deg2rad(yte_deg)\n",
    "\n",
    "image_height, image_width, n_channels = xtr.shape[1:]\n",
    "flatten_x_shape = xtr[0].flatten().shape[0]\n",
    "phi_shape = yte_bit.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_u = 8\n",
    "cvae = CVAE(n_hidden_units=n_u)\n",
    "cvae_ckpt_path = 'logs/best_models/cvae/3/cvae.full_model.trial_2.best.weights.hdf5'\n",
    "cvae.full_model.load_weights(cvae_ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAAD error (validation) : 26.917997 ± 1.178502SEM\n",
      "ELBO (validation) : -0.700545 ± 0.049847SEM\n",
      "KL-div (validation) : 0.350774 ± 0.019146SEM\n",
      "MAAD error (test) : 27.201755 ± 1.218712SEM\n",
      "ELBO (test) : -0.717721 ± 0.053369SEM\n",
      "KL-div (test) : 0.322192 ± 0.018516SEM\n"
     ]
    }
   ],
   "source": [
    "results_cvae = dict()\n",
    "#results_cvae['train'] = cvaekl.evaluate(xtr, ytr_deg, 'train')\n",
    "results_cvae['validation'] = cvae.evaluate(xval, yval_deg, 'validation')\n",
    "results_cvae['test'] = cvae.evaluate(xte, yte_deg, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian log-likelihood\n",
    "\n",
    "$\\log L(x)= -\\frac{1}{2} \\left( \\log (|\\boldsymbol\\Sigma|\\,) + (\\mathbf{x}-\\boldsymbol\\mu)^{\\rm T}\\boldsymbol\\Sigma^{-1}(\\mathbf{x}-\\boldsymbol\\mu) + n\\log(2\\pi) \\right)$\n",
    "\n",
    "In case $\\boldsymbol\\Sigma = diag(\\sigma_1^2, \\dots, \\sigma_n^2)$\n",
    "\n",
    "$\\log L(x)= -\\frac{1}{2} \\left( (\\sum_{i=1}^{n}{\\log \\sigma^2_i}) + \\sum_{i=1}^{n}{\\frac{(x_i-\\mu_i)^2}{\\sigma^2_i}} + n\\log(2\\pi) \\right)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model_samples(cvae, x, y, n_samples=10):\n",
    "    \n",
    "    n_points = x.shape[0]\n",
    "    \n",
    "    x_tiled = np.repeat(x_ex, repeats=n_samples, axis=0)\n",
    "    y_tiled = np.repeat(y_ex, repeats=n_samples, axis=0)\n",
    "    \n",
    "    output = cvae.get_full_output(x, y)\n",
    "    mu_prior = output['mu_prior']\n",
    "    std_prior = np.exp(output['log_sigma_prior'] / 2)\n",
    "    mu_encoder = output['mu_encoder']\n",
    "    std_encoder = np.exp(output['log_sigma_encoder'] / 2)\n",
    "    u_encoder = output['u_encoder']\n",
    "    mu_pred = output['mu_pred']\n",
    "    \n",
    "    u_samples = np.zeros([n_points, n_samples, cvae.n_u])\n",
    "    \n",
    "    mu_preds = np.zeros([n_points, n_samples, 2])\n",
    "    kappa_preds = np.zeros([n_points, n_samples, 1])\n",
    "        \n",
    "    for sid in range(0, n_samples):\n",
    "        \n",
    "        kappa_preds[:, sid, :] = output['kappa_pred']\n",
    "        \n",
    "        #vm_likelihood[:, sid] = np.squeeze(np.exp(von_mises_log_likelihood_np(y, mu_pred, kappa_pred)))\n",
    "        u_samples[:, sid, :] = u_encoder\n",
    "    \n",
    "    prior_log_likelihood =  gaussian_log_likelihood_np(mu_prior, std_prior, u_samples)\n",
    "    encoder_log_likelihood = gaussian_log_likelihood_np(mu_encoder, std_encoder, u_samples)\n",
    "    \n",
    "    sample_weight = np.exp(prior_log_likelihood - encoder_log_likelihood)\n",
    "    \n",
    "    importance_likelihoods = np.log(np.mean(vm_likelihood*sample_weight, axis=1))\n",
    "    \n",
    "    return u_samples, mu_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Improtance sampling\n",
    "$ p(\\phi| x) \\approx \\frac{1}{S} \\sum_{i=1}^{S}{\\frac{ p(\\phi | x, u_i) p(u_i|x)  }{ q(u_i| x, \\phi)}}$\n",
    "\n",
    "where\n",
    "\n",
    "$ p(u|x) \\sim \\mathcal{N}(\\mu_1(x), \\sigma_1(x)) $\n",
    "\n",
    "$ q(u|x,\\phi) \\sim \\mathcal{N}(\\mu_2(x, \\phi), \\sigma_2(x, \\phi)) $\n",
    "\n",
    "$ p(\\phi|x, u) \\sim \\mathcal{VM}(\\mu(x,u), \\kappa(x,u)) $\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_u = 8\n",
    "cvae_ckpt_path = 'logs/best_models/cvae/importance_sampling/cvae.full_model.trial_0.best.weights.hdf5'\n",
    "\n",
    "cvae = CVAE_mod(n_hidden_units=n_u, n_samples=10)\n",
    "#cvae.full_model.load_weights(cvae_ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ex = xtr[0:10]\n",
    "y_ex = ytr_bit[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 [==============================] - 4s - loss: 11.4827     \n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s - loss: 8.1388     \n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s - loss: 15.5820     \n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s - loss: 8.9747     \n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s - loss: 13.3390     \n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s - loss: 7.1048     \n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s - loss: 6.9067     \n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s - loss: 5.0953     \n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s - loss: 4.8809     \n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s - loss: 5.1355     \n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s - loss: 4.1057     \n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s - loss: 4.0184     \n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s - loss: 3.5989     \n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s - loss: 2.8633     \n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s - loss: 2.6534     \n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s - loss: 2.3312     \n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s - loss: 2.4687     \n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s - loss: 2.2727     \n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s - loss: 2.1617     \n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s - loss: 2.1270     \n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s - loss: 2.0529     \n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s - loss: 1.9672     \n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s - loss: 1.9325     \n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s - loss: 1.9119     \n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s - loss: 1.8580     \n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s - loss: 1.8470     \n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s - loss: 1.8395     \n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s - loss: 1.8530     \n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s - loss: 1.8449     \n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s - loss: 1.8163     \n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s - loss: 1.8182     \n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s - loss: 1.8131     \n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s - loss: 1.7943     \n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s - loss: 1.7792     \n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s - loss: 1.7861     \n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s - loss: 1.8092     \n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s - loss: 1.8178     \n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s - loss: 1.7970     \n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s - loss: 1.7852     \n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s - loss: 1.8127     \n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s - loss: 1.7853     \n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s - loss: 1.7898     \n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s - loss: 1.8068     \n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s - loss: 1.8113     \n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s - loss: 1.8000     \n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s - loss: 1.7981     \n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s - loss: 1.7828     \n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s - loss: 1.8073     \n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s - loss: 1.7881     \n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s - loss: 1.7847     \n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s - loss: 1.8039     \n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s - loss: 1.8366     \n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s - loss: 1.7704     \n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s - loss: 1.7952     \n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s - loss: 1.7814     \n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 1s - loss: 1.8165     \n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 1s - loss: 1.7687     \n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s - loss: 1.7735     - ETA: 0s - loss\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s - loss: 1.7683     \n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s - loss: 1.7846     \n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s - loss: 1.7846     \n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s - loss: 1.7738     \n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s - loss: 1.7861     \n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s - loss: 1.7814     \n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s - loss: 1.7826     \n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s - loss: 1.7786     \n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s - loss: 1.7850     \n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s - loss: 1.8349     \n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s - loss: 1.7851     \n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s - loss: 1.7787     \n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s - loss: 1.7677     \n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s - loss: 1.7812     \n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s - loss: 1.7762     \n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s - loss: 1.7754     \n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s - loss: 1.7637     \n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s - loss: 1.7662     \n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s - loss: 1.7843     \n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s - loss: 1.7665     \n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s - loss: 1.7655     \n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s - loss: 1.7716     \n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s - loss: 1.7591     \n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 1s - loss: 1.7657     \n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s - loss: 1.8158     \n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s - loss: 1.7639     \n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s - loss: 1.7674     \n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s - loss: 1.7679     \n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s - loss: 1.7811     \n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s - loss: 1.7647     \n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s - loss: 1.7740     \n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s - loss: 1.7614     \n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s - loss: 1.7647     \n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s - loss: 1.7723     \n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s - loss: 1.7539     \n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s - loss: 1.7715     \n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s - loss: 1.7603     \n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s - loss: 1.7572     \n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s - loss: 1.7604     \n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s - loss: 1.7587     \n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s - loss: 1.7868     \n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 1s - loss: 1.8250     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x139305eb8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvae.full_model.fit([x_ex, y_ex], [y_ex], batch_size=1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = cvae.parse_output_np(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01504882, -0.09004651,  0.04421894,  0.03139315,  0.07110171,\n",
       "       -0.10503473,  0.08417977,  0.03725082], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['log_sigma_prior'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.30227384,  0.85442054,  0.09892523,  0.42520851,  0.08735669,\n",
       "        0.70252037,  0.07263037,  0.19221827], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['log_sigma_encoder'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04456184, -0.09462242, -0.04436426, -0.0434421 ,  0.03611296,\n",
       "        0.13465738, -0.06221258, -0.01118772], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['mu_prior'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.23432055,  0.85917366,  0.15957892,  0.07298554,  0.03797113,\n",
       "       -1.15434086,  0.20611146, -0.01505825], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['mu_encoder'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 210.,   32.,  165.,  173.,  194.,  175.,  189.,  151.,  156.,  162.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bit2deg(y_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  88.12188721,  172.05938721,   51.73916626,  179.8581543 ,\n",
       "         62.88040161,  160.93273926,   73.43035889,   50.28204346,\n",
       "         59.31417847,   86.07574463,   51.10168457,   61.04406738,\n",
       "        164.83843994,  162.93341064,   51.42330933,   54.99816895,\n",
       "         50.44769287,   50.40542603,   74.69128418,   56.878479  ,\n",
       "         50.68270874,   53.98291016,   48.85910034,   92.55584717,\n",
       "         54.3999939 ,   52.50692749,  161.90509033,   50.86749268,\n",
       "         52.02371216,   54.61517334,   50.65472412,   49.58602905,\n",
       "         50.37402344,   50.93649292,   59.81936646,  178.65112305,\n",
       "        143.88729858,   58.45568848,   50.40621948,  153.06958008,\n",
       "         49.99649048,   54.9180603 ,   54.14080811,   52.07531738,\n",
       "         54.61877441,   53.75006104,  161.83502197,  154.46856689,\n",
       "         51.94525146,  110.41064453,  163.09326172,   49.26519775,\n",
       "        165.05969238,  113.61166382,  155.49731445,  109.4119873 ,\n",
       "        138.53305054,   55.98321533,   50.98309326,   53.87738037,\n",
       "         51.5050354 ,   59.86383057,  152.19085693,   50.7522583 ,\n",
       "        159.09350586,   56.36959839,   51.08837891,  175.63232422,\n",
       "         77.68692017,   62.57479858,  155.97503662,   55.02807617,\n",
       "         50.74627686,  170.72833252,   81.90432739,  140.16186523,\n",
       "         51.44927979,   86.58227539,   58.96017456,   50.20532227,\n",
       "         53.23947144,   54.95153809,   49.34185791,   51.40356445,\n",
       "        206.49575806,   66.59106445,   53.37957764,  162.87762451,\n",
       "        170.6204834 ,   79.83480835,   79.9024353 ,   67.48352051,\n",
       "        166.51824951,  152.58013916,   59.04199219,   52.55303955,\n",
       "         50.25985718,   70.65194702,  126.9887085 ,  114.01712036,\n",
       "         71.97247314,   50.34332275,   53.70401001,  122.14511108,\n",
       "        140.49273682,   99.4074707 ,   51.97186279,  172.9753418 ,\n",
       "         50.04360962,   63.93774414,  165.72198486,   55.45953369,\n",
       "        158.42901611,  156.63531494,   84.04171753,   50.41189575,\n",
       "        111.31454468,  146.78387451,   69.34176636,  158.2097168 ,\n",
       "         57.75894165,   50.77587891,   57.51361084,   50.50012207,\n",
       "         54.26251221,  174.13476562,   59.81365967,   54.00982666], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bit2deg(out['mu_preds'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_ph = tf.placeholder(dtype=tf.float32, shape=[None, 152])\n",
    "y_ph = tf.placeholder(dtype=tf.float32, shape=[None, 2])\n",
    "\n",
    "impll_tf = cvae.importance_log_likelihood_tf(y_ph, out_ph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    ll = impll_tf.eval(feed_dict={out_ph:out, y_ph:y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8896326"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ll"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
