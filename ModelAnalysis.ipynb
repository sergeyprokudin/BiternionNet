{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Lambda, Flatten, Activation, Merge, Concatenate, Add\n",
    "from keras import layers\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Model, Sequential\n",
    "from keras.objectives import binary_crossentropy\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import sem\n",
    "from scipy.spatial.distance import squareform, pdist\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from models import vgg\n",
    "from models.cvae import CVAE\n",
    "from models.cvae_mod import CVAE as CVAE_mod\n",
    "from utils.losses import von_mises_log_likelihood_np\n",
    "from utils.angles import deg2bit, bit2deg\n",
    "from utils.losses import mad_loss_tf, cosine_loss_tf, von_mises_loss_tf, maad_from_deg\n",
    "from utils.losses import gaussian_kl_divergence_tf, gaussian_kl_divergence_np\n",
    "from utils.losses  import von_mises_log_likelihood_tf, von_mises_log_likelihood_np\n",
    "from utils.towncentre import load_towncentre\n",
    "from utils.experiements import get_experiment_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train samples: 6916\n",
      "Number of validation samples: 874\n",
      "Number of test samples: 904\n"
     ]
    }
   ],
   "source": [
    "xtr, ytr_deg, xval, yval_deg, xte, yte_deg = load_towncentre('data/TownCentre.pkl.gz', canonical_split=True, verbose=1)\n",
    "\n",
    "image_height, image_width = xtr.shape[1], xtr.shape[2]\n",
    "ytr_bit = deg2bit(ytr_deg)\n",
    "yval_bit = deg2bit(yval_deg)\n",
    "yte_bit = deg2bit(yte_deg)\n",
    "yte_rad = np.deg2rad(yte_deg)\n",
    "\n",
    "image_height, image_width, n_channels = xtr.shape[1:]\n",
    "flatten_x_shape = xtr[0].flatten().shape[0]\n",
    "phi_shape = yte_bit.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading pre-trained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Biternion-VGG (Log-likelihood, fixed $\\kappa=3$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg_fixed_kappa = vgg.BiternionVGG(image_height=image_height,\n",
    "                                   image_width=image_width,\n",
    "                                   n_channels=3,\n",
    "                                   predict_kappa=False,\n",
    "                                   fixed_kappa_value=3.0)\n",
    "\n",
    "vgg_fixed_kappa.model.load_weights('logs/best_models/fixed_kappa/vgg_bit_vm_likelihood_town.best.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAAD error (validation) : 22.728342 ± 0.990586SEM\n",
      "log-likelihood (validation) : -0.870462 ± 0.035802SEM\n",
      "MAAD error (test) : 24.155143 ± 1.088582SEM\n",
      "log-likelihood (test) : -0.929270 ± 0.039672SEM\n"
     ]
    }
   ],
   "source": [
    "results_fixed = dict()\n",
    "#results_fixed['train'] = vgg_fixed_kappa.evaluate(xtr, ytr_deg, 'train')\n",
    "results_fixed['validation'] = vgg_fixed_kappa.evaluate(xval, yval_deg, 'validation')\n",
    "results_fixed['test'] = vgg_fixed_kappa.evaluate(xte, yte_deg, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Biternion-VGG (Log-likelihood, learned $\\kappa$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg_learned_kappa = vgg.BiternionVGG(image_height=image_height,\n",
    "                                     image_width=image_width,\n",
    "                                     n_channels=3,\n",
    "                                     predict_kappa=True)\n",
    "\n",
    "vgg_learned_kappa.model.load_weights('logs/best_models/learned_kappa/vgg_bit_vm_likelihood_town.best.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAAD error (validation) : 24.398405 ± 1.090128SEM\n",
      "log-likelihood (validation) : -0.802889 ± 0.078568SEM\n",
      "MAAD error (test) : 24.327137 ± 1.095842SEM\n",
      "log-likelihood (test) : -0.764323 ± 0.066594SEM\n"
     ]
    }
   ],
   "source": [
    "results_learned = dict()\n",
    "#results_learned['train'] = vgg_learned_kappa.evaluate(xtr, ytr_deg, 'train')\n",
    "results_learned['validation'] = vgg_learned_kappa.evaluate(xval, yval_deg, 'validation')\n",
    "results_learned['test'] = vgg_learned_kappa.evaluate(xte, yte_deg, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Biternion-VGG (cosine-loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg_cosine = vgg.BiternionVGG(image_height=image_height,\n",
    "                              image_width=image_width,\n",
    "                              n_channels=3,\n",
    "                              predict_kappa=False,\n",
    "                              fixed_kappa_value=3.0)\n",
    "\n",
    "vgg_cosine.model.load_weights('logs/best_models/cosine/vgg_bit_cosine_town.best.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAAD error (validation) : 21.833931 ± 0.966800SEM\n",
      "log-likelihood (validation) : -0.843196 ± 0.034713SEM\n",
      "MAAD error (test) : 24.108348 ± 1.069605SEM\n",
      "log-likelihood (test) : -0.926001 ± 0.038936SEM\n"
     ]
    }
   ],
   "source": [
    "results_cosine = dict()\n",
    "#results_cosine['train'] = vgg_cosine.evaluate(xtr, ytr_deg, 'train')\n",
    "results_cosine['validation'] = vgg_cosine.evaluate(xval, yval_deg, 'validation')\n",
    "results_cosine['test'] = vgg_cosine.evaluate(xte, yte_deg, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Biternion-VGG (Von-Mises loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg_vm = vgg.BiternionVGG(image_height=image_height,\n",
    "                          image_width=image_width,\n",
    "                          n_channels=3,\n",
    "                          predict_kappa=False,\n",
    "                          fixed_kappa_value=3.0)\n",
    "\n",
    "vgg_vm.model.load_weights('logs/best_models/von_mises/vgg_bit_von_mises_town.best.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAAD error (validation) : 22.974047 ± 0.999363SEM\n",
      "log-likelihood (validation) : -0.883493 ± 0.036697SEM\n",
      "MAAD error (test) : 24.156092 ± 1.083819SEM\n",
      "log-likelihood (test) : -0.925846 ± 0.039583SEM\n"
     ]
    }
   ],
   "source": [
    "results_vm = dict()\n",
    "#results_vm['train'] = vgg_vm.evaluate(xtr, ytr_deg, 'train')\n",
    "results_vm['validation'] = vgg_vm.evaluate(xval, yval_deg, 'validation')\n",
    "results_vm['test'] = vgg_vm.evaluate(xte, yte_deg, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def maximum_expected_utility(ypreds):\n",
    "    ix = np.argmin(np.sum(squareform(pdist(ypreds, 'euclidean')), axis=1))\n",
    "    return float(ypreds[ix])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CVAE model - regular training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_u = 8\n",
    "cvae = CVAE(n_hidden_units=n_u)\n",
    "cvae_ckpt_path = 'logs/best_models/cvae/cvae.full_model.overall_best.weights.hdf5'\n",
    "cvae.full_model.load_weights(cvae_ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAAD error (validation) : 23.796661 ± 1.075040SEM\n",
      "ELBO (validation) : -0.595410 ± 0.039326SEM\n",
      "KL-div (validation) : 0.000102 ± 0.000043SEM\n",
      "MAAD error (test) : 23.377776 ± 1.064720SEM\n",
      "ELBO (test) : -0.665743 ± 0.062994SEM\n",
      "KL-div (test) : 0.000109 ± 0.000045SEM\n"
     ]
    }
   ],
   "source": [
    "results_cvae = dict()\n",
    "# results_cvae['train'] = cvae_best.evaluate(xtr, ytr_deg, 'train')\n",
    "results_cvae['validation'] = cvae.evaluate(xval, yval_deg, 'validation')\n",
    "results_cvae['test'] = cvae.evaluate(xte, yte_deg, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = cvae.full_model.predict([xte, yte_bit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mu_prior = y_pred[:, 0:n_u]\n",
    "log_sigma_prior = y_pred[:, n_u:n_u*2]\n",
    "mu_encoder = y_pred[:, n_u*2:n_u*3]\n",
    "log_sigma_encoder = y_pred[:, n_u*3:n_u*4]\n",
    "mu_pred = y_pred[:, n_u*4:n_u*4+2]\n",
    "kappa_pred = y_pred[:, n_u*4+2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_decoder = cvae.decoder_model.predict(xte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_samples = 10\n",
    "\n",
    "cvae_mu_rad_preds  = np.zeros([n_samples, xte.shape[0], 1])\n",
    "cvae_kappa_preds  = np.zeros([n_samples, xte.shape[0], 1])\n",
    "cvae_mu_bit_preds = np.zeros([n_samples, xte.shape[0], 2])\n",
    "\n",
    "for i in range(0, n_samples):\n",
    "    cvae_preds = cvae.decoder_model.predict(xte)\n",
    "    cvae_mu_bit_preds[i,:,:] = cvae_preds[:,0:2]\n",
    "    cvae_mu_rad_preds[i,:,:] = np.deg2rad(bit2deg(cvae_preds[:,0:2])).reshape(-1,1)\n",
    "    cvae_kappa_preds[i,:,:] = cvae_preds[:,2].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAAD error (test, cvae-MAE) : 23.468769 ± 1.065225SEM\n",
      "Monte-Carlo log-likelihood (test, cvae) : -0.668994 ± 0.063274SEM\n"
     ]
    }
   ],
   "source": [
    "mc_log_like = [np.mean(von_mises_log_likelihood_np(np.tile(yte_bit[i], [n_samples, 1]), cvae_mu_bit_preds[:,i,0:2], cvae_kappa_preds[:,i,0].reshape(-1,1))) for i in range(0, cvae_preds.shape[0])]\n",
    "cvae_mu_rad_preds_mae = [maximum_expected_utility(cvae_mu_rad_preds[:,i,:]) for i in range(0, cvae_mu_rad_preds.shape[1])]\n",
    "maad_errors = maad_from_deg(np.rad2deg(cvae_mu_rad_preds_mae), yte_deg)\n",
    "print(\"MAAD error (test, cvae-MAE) : %f ± %fSEM\" % (np.mean(maad_errors), sem(maad_errors)))\n",
    "print(\"Monte-Carlo log-likelihood (test, cvae) : %f ± %fSEM\" % (np.mean(mc_log_like), sem(mc_log_like)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CVAE model - trained with KL annelaing (0.5->0.75->1.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_u = 8\n",
    "cvaekl = CVAE_mod(n_hidden_units=n_u)\n",
    "cvaekl_ckpt_path = 'logs/best_models/cvae/kl_reduction_exepriments/4/cvae.full_model.overall_best.weights.hdf5'\n",
    "cvaekl.full_model.load_weights(cvaekl_ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAAD error (validation) : 15.337484 ± 0.417334SEM\n",
      "ELBO (validation) : -1.375695 ± 0.053010SEM\n",
      "KL-div (validation) : 1.057518 ± 0.042646SEM\n",
      "MAAD error (test) : 15.605149 ± 0.679577SEM\n",
      "ELBO (test) : -1.529803 ± 0.072726SEM\n",
      "KL-div (test) : 1.129564 ± 0.051624SEM\n"
     ]
    }
   ],
   "source": [
    "results_cvaekl = dict()\n",
    "# results_cvae['train'] = cvae_best.evaluate(xtr, ytr_deg, 'train')\n",
    "results_cvaekl['validation'] = cvaekl.evaluate(xval, yval_deg, 'validation')\n",
    "results_cvaekl['test'] = cvaekl.evaluate(xte, yte_deg, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Maximum Expected Utility for MAAD calculation and Monte-Carlo estimation of log-likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_estimates(cvae_model, x, y_bit,  n_samples=1):\n",
    "    mu_rad_preds  = np.zeros([n_samples, x.shape[0], 1])\n",
    "    mu_bit_preds = np.zeros([n_samples, x.shape[0], 2])\n",
    "    kappa_preds  = np.zeros([n_samples, x.shape[0], 1])\n",
    "    marg_loglike_preds = np.zeros([n_samples, x.shape[0], 1])\n",
    "    kl_preds = np.zeros([n_samples, x.shape[0], 1])\n",
    "    elbo_preds = np.zeros([n_samples, x.shape[0], 1])\n",
    "\n",
    "    mu_rad_preds_dec  = np.zeros([n_samples, x.shape[0], 1])\n",
    "    mu_bit_preds_dec = np.zeros([n_samples, x.shape[0], 2])\n",
    "    kappa_preds_dec  = np.zeros([n_samples, x.shape[0], 1])\n",
    "\n",
    "    for i in range(0, n_samples):\n",
    "        preds = cvae_model.full_model.predict([x, y_bit], batch_size=500)\n",
    "        mu_bit_preds[i,:,:] =  preds[:, n_u*4:n_u*4+2]\n",
    "        mu_rad_preds[i,:,:] = np.deg2rad(bit2deg(preds[:, n_u*4:n_u*4+2])).reshape(-1,1)\n",
    "        kappa_preds[i,:,:] = preds[:, n_u*4+2:].reshape(-1,1)\n",
    "        elbo, marg_log_likelihood, kl = cvaekl._cvae_elbo_loss_np(y_bit, preds)\n",
    "        marg_loglike_preds[i,:,:] = marg_log_likelihood\n",
    "        kl_preds[i,:,:] = kl\n",
    "        elbo_preds[i,:,:] = elbo \n",
    "        preds_dec = cvae_model.decoder_model.predict(x, batch_size=500)\n",
    "        mu_bit_preds_dec[i,:,:] =  preds_dec[:, 0:2]\n",
    "        mu_rad_preds_dec[i,:,:] = np.deg2rad(bit2deg(preds_dec[:, 0:2])).reshape(-1,1)\n",
    "        kappa_preds_dec[i,:,:] = preds_dec[:, 2:].reshape(-1,1)\n",
    "\n",
    "    res = dict()\n",
    "    \n",
    "    res['mu_rad_preds'] = mu_rad_preds\n",
    "    res['mu_bit_preds'] = mu_bit_preds\n",
    "    res['kappa_preds'] = kappa_preds\n",
    "    res['marg_loglike_preds'] = marg_loglike_preds\n",
    "    res['kl_preds'] = kl_preds\n",
    "    res['elbo_preds'] = elbo_preds\n",
    "    res['mu_rad_preds_dec'] = mu_rad_preds_dec\n",
    "    res['mu_bit_preds_dec'] = mu_bit_preds_dec\n",
    "    res['kappa_preds_dec'] = kappa_preds_dec  \n",
    "    res['mu_rad_preds_mae'] = [maximum_expected_utility(mu_rad_preds[:,i,:]) for i in range(0, mu_rad_preds.shape[1])]\n",
    "    res['mu_rad_preds_dec_mae'] = [maximum_expected_utility(mu_rad_preds_dec[:,i,:]) for i in range(0, mu_rad_preds_dec.shape[1])]\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 50\n",
    "\n",
    "res_val = get_estimates(cvaekl, xval, yval_bit, n_samples=n_samples)\n",
    "res_test = get_estimates(cvaekl, xte, yte_bit, n_samples=n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELBO (validation, cvaekl) : -1.343310 ± 0.007494SEM\n",
      "ELBO (test, cvaekl) : -1.278379 ± 0.008119SEM\n",
      "KL-divergence (validation, cvaekl) : 1.057518 ± 0.006028SEM\n",
      "KL-divergence (test, cvaekl) : 1.129564 ± 0.007297SEM\n",
      "MAAD error, prior sampler (validation, cvaekl-MAE) : 30.863716 ± 1.237921SEM\n",
      "MAAD error, prior sampler (test, cvaekl-MAE) : 30.849527 ± 1.221775SEM\n",
      "MAAD error, encoder sampler (validation, cvaekl-MAE) : 9.187199 ± 0.315359SEM\n",
      "MAAD error, encoder sampler (test, cvaekl-MAE) : 7.940475 ± 0.193001SEM\n"
     ]
    }
   ],
   "source": [
    "print(\"ELBO (validation, cvaekl) : %f ± %fSEM\" % (np.mean(res_val['elbo_preds']), sem(res_val['elbo_preds'],axis=None)))\n",
    "print(\"ELBO (test, cvaekl) : %f ± %fSEM\" % (np.mean(res_test['elbo_preds']), sem(res_test['elbo_preds'],axis=None)))\n",
    "print(\"KL-divergence (validation, cvaekl) : %f ± %fSEM\" % (np.mean(res_val['kl_preds']), sem(res_val['kl_preds'],axis=None)))\n",
    "print(\"KL-divergence (test, cvaekl) : %f ± %fSEM\" % (np.mean(res_test['kl_preds']), sem(res_test['kl_preds'],axis=None)))\n",
    "maad_errors_val = maad_from_deg(np.rad2deg(res_val['mu_rad_preds_dec_mae']), yval_deg)\n",
    "print(\"MAAD error, prior sampler (validation, cvaekl-MAE) : %f ± %fSEM\" % (np.mean(maad_errors_val), sem(maad_errors_val)))\n",
    "maad_errors_test = maad_from_deg(np.rad2deg(res_test['mu_rad_preds_dec_mae']), yte_deg)\n",
    "print(\"MAAD error, prior sampler (test, cvaekl-MAE) : %f ± %fSEM\" % (np.mean(maad_errors_test), sem(maad_errors_test)))\n",
    "maad_errors_val = maad_from_deg(np.rad2deg(res_val['mu_rad_preds_mae']), yval_deg)\n",
    "print(\"MAAD error, encoder sampler (validation, cvaekl-MAE) : %f ± %fSEM\" % (np.mean(maad_errors_val), sem(maad_errors_val)))\n",
    "maad_errors_test = maad_from_deg(np.rad2deg(res_test['mu_rad_preds_mae']), yte_deg)\n",
    "print(\"MAAD error, encoder sampler (test, cvaekl-MAE) : %f ± %fSEM\" % (np.mean(maad_errors_test), sem(maad_errors_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_preds_tr = cvaekl.encoder_model.predict([xtr, ytr_bit])\n",
    "encoder_preds_val = cvaekl.encoder_model.predict([xval, yval_bit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils.losses import gaussian_kl_divergence_tf, gaussian_kl_divergence_np\n",
    "\n",
    "def prior_kl_div_tf(y_true, y_pred):\n",
    "    mu_encoder = y_true[:, 0:n_u]\n",
    "    log_sigma_encoder = y_true[:, n_u:n_u*2]\n",
    "    mu_prior = y_pred[:, 0:n_u]\n",
    "    log_sigma_prior = y_pred[:, n_u:n_u*2]\n",
    "    kl = gaussian_kl_divergence_tf(mu_encoder, log_sigma_encoder, mu_prior, log_sigma_prior)\n",
    "    return kl\n",
    "\n",
    "def prior_kl_div_np(y_true, y_pred):\n",
    "    mu_encoder = y_true[:, 0:n_u]\n",
    "    log_sigma_encoder = y_true[:, n_u:n_u*2]\n",
    "    mu_prior = y_pred[:, 0:n_u]\n",
    "    log_sigma_prior = y_pred[:, n_u:n_u*2]\n",
    "    kl = gaussian_kl_divergence_np(mu_encoder, log_sigma_encoder, mu_prior, log_sigma_prior)\n",
    "    return kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.65948033"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(prior_kl_div_np(encoder_preds, prior_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvaekl.prior_model.compile(optimizer='adam', loss=prior_kl_div_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6916 samples, validate on 874 samples\n",
      "Epoch 1/25\n",
      "6916/6916 [==============================] - 56s - loss: 0.5727 - val_loss: 1.5060\n",
      "Epoch 2/25\n",
      "6916/6916 [==============================] - 53s - loss: 0.5436 - val_loss: 1.1521\n",
      "Epoch 3/25\n",
      "6916/6916 [==============================] - 53s - loss: 0.4967 - val_loss: 1.1596\n",
      "Epoch 4/25\n",
      "6916/6916 [==============================] - 53s - loss: 0.4902 - val_loss: 1.0742\n",
      "Epoch 5/25\n",
      "6916/6916 [==============================] - 53s - loss: 0.4764 - val_loss: 1.1841\n",
      "Epoch 6/25\n",
      "6916/6916 [==============================] - 53s - loss: 0.4605 - val_loss: 1.4282\n",
      "Epoch 7/25\n",
      "6916/6916 [==============================] - 53s - loss: 0.4558 - val_loss: 1.4821\n",
      "Epoch 8/25\n",
      "6916/6916 [==============================] - 53s - loss: 0.4343 - val_loss: 1.2497\n",
      "Epoch 9/25\n",
      "6916/6916 [==============================] - 53s - loss: 0.4035 - val_loss: 1.0730\n",
      "Epoch 10/25\n",
      "6916/6916 [==============================] - 53s - loss: 0.4115 - val_loss: 1.1088\n",
      "Epoch 11/25\n",
      "6916/6916 [==============================] - 53s - loss: 0.3716 - val_loss: 1.1150\n",
      "Epoch 12/25\n",
      "2250/6916 [========>.....................] - ETA: 35s - loss: 0.3692"
     ]
    }
   ],
   "source": [
    "cvaekl.prior_model.fit([xtr, ytr_bit], [encoder_preds_tr], batch_size=50, epochs=25,\n",
    "                          validation_data=([xval, yval_bit], encoder_preds_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving predictions from different model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vm_preds = vgg_vm.model.predict(xte)\n",
    "vm_preds_mu_rad = np.deg2rad(bit2deg(vm_preds))\n",
    "vm_preds_kappa = np.ones([xte.shape[0],1])*3\n",
    "vm_preds_likelihoods = von_mises_log_likelihood_np(yte_bit, vm_preds[:,0:2], vm_preds_kappa)\n",
    "\n",
    "fixed_preds = vgg_fixed_kappa.model.predict(xte)\n",
    "fixed_preds_mu_rad = np.deg2rad(bit2deg(fixed_preds))\n",
    "fixed_preds_kappa = np.ones([xte.shape[0],1])*3\n",
    "fixed_preds_likelihoods = von_mises_log_likelihood_np(yte_bit, fixed_preds[:,0:2], fixed_preds_kappa)\n",
    "\n",
    "learned_preds = vgg_learned_kappa.model.predict(xte)\n",
    "learned_preds_mu_rad = np.deg2rad(bit2deg(learned_preds[:,0:2]))\n",
    "learned_preds_kappa = learned_preds[:,2:]\n",
    "learned_preds_likelihoods = von_mises_log_likelihood_np(yte_bit, learned_preds[:,0:2], learned_preds_kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils.losses import log_bessel_approx_np\n",
    "\n",
    "def vm_pdf(vals, mu_rad, kappa):\n",
    "    return np.exp(kappa * np.cos(vals-mu_rad)) / (2* np.pi * np.exp(log_bessel_approx_np(kappa)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def plot_vm_dists(fid):\n",
    "    x_vals = np.arange(0, 2*np.pi, 0.01)\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 7, figsize=(25, 5))\n",
    "    \n",
    "    axs[0].imshow(xte[fid])\n",
    "    \n",
    "    def _plt_vgg(axis, mu_rad_preds, kappa_preds, method_name):\n",
    "        axis.set_xticks(([0., .5*np.pi, np.pi, 1.5*np.pi, 2*np.pi]))\n",
    "        axis.set_xticklabels([\"$0$\", r\"$\\frac{\\pi}{2}$\", r\"$\\pi$\", r\"$\\frac{3\\pi}{2}$\", r\"$2\\pi$\"]) \n",
    "        axis.set_xlim([-0.001, 2*np.pi+0.001])\n",
    "        axis.plot(x_vals, np.squeeze(vm_pdf(x_vals, mu_rad_preds[fid], kappa_preds[fid])))\n",
    "        axis.axvline(yte_rad[fid], color='red')\n",
    "        axis.set_title(\"%s \" % method_name)\n",
    "        axis.set_ylim([0, 2.0])\n",
    "        \n",
    "    def _plt_cvae(axis, cvae_mu_rad_preds, cvae_kappa_preds, method_name, plot_mixture=False):\n",
    "        axis.set_xticks(([0., .5*np.pi, np.pi, 1.5*np.pi, 2*np.pi]))\n",
    "        axis.set_xticklabels([\"$0$\", r\"$\\frac{\\pi}{2}$\", r\"$\\pi$\", r\"$\\frac{3\\pi}{2}$\", r\"$2\\pi$\"]) \n",
    "        axis.set_xlim([-0.001, 2*np.pi+0.001])\n",
    "        vm_vals = np.zeros([n_samples, x_vals.shape[0]])\n",
    "        if plot_mixture:\n",
    "            for sid in range(0, n_samples):\n",
    "                vm_vals[sid, :] = vm_pdf(x_vals, cvae_mu_rad_preds[sid, fid], cvae_kappa_preds[sid, fid])\n",
    "            axis.plot(x_vals, np.mean(vm_vals, axis=0))\n",
    "        else:\n",
    "            for sid in range(0, n_samples):\n",
    "                axis.plot(x_vals, np.squeeze(vm_pdf(x_vals, cvae_mu_rad_preds[sid, fid], cvae_kappa_preds[sid, fid])))  \n",
    "        axis.axvline(yte_rad[fid], color='red')\n",
    "        axis.set_title(\"%s \" % method_name)\n",
    "        axis.set_ylim([0, 2.0])\n",
    "        \n",
    "    _plt_vgg(axs[1], fixed_preds_mu_rad, fixed_preds_kappa, 'original (Von-Mises loss)')\n",
    "    _plt_vgg(axs[2], fixed_preds_mu_rad, fixed_preds_kappa, 'fixed kappa')\n",
    "    _plt_vgg(axs[3], learned_preds_mu_rad, learned_preds_kappa, 'learned kappa')\n",
    "    _plt_cvae(axs[4], cvae_mu_rad_preds, cvae_kappa_preds, \"CVAE (normal)\")\n",
    "    _plt_cvae(axs[5], res_test['mu_rad_preds'],  res_test['kappa_preds'], \"CVAE (KL annealing)\")\n",
    "    _plt_cvae(axs[6], res_test['mu_rad_preds'], res_test['kappa_preds'], \"CVAE (KL annealing, mixture density)\", plot_mixture=True)\n",
    "    fig.suptitle(\"frame id =%d\" %fid)\n",
    "    #plt.plot((ytr_deg, x2), (y1, y2), 'k-')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  dataset desc http://www.robots.ox.ac.uk/~lav/Papers/benfold_reid_iccv2011/benfold_reid_iccv2011.pdf\n",
    "#####  https://www.youtube.com/watch?v=eupXTJM_TAw (Demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "\n",
    "for fid in range(0, 100):\n",
    "    plot_vm_dists(fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cvae_preds_full = cvae.full_model.predict([xte, yte_bit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_prior = cvae_preds_full[:, 0:cvae_best.n_u]\n",
    "log_sigma_prior = cvae_preds_full[:, cvae_best.n_u:cvae_best.n_u*2]\n",
    "mu_encoder = cvae_preds_full[:, cvae_best.n_u*2:cvae_best.n_u*3]\n",
    "log_sigma_encoder = cvae_preds_full[:, cvae_best.n_u*3:cvae_best.n_u*4]\n",
    "mu_pred = cvae_preds_full[:, cvae_best.n_u*4:cvae_best.n_u*4+2]\n",
    "kappa_pred = cvae_preds_full[:, cvae_best.n_u*4+2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.exp(log_sigma_prior[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The problem is that encoder and prior generate exactly the same distributions for each input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ p(u|x) = q(u|x,\\phi) = p(u)$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mu_prior[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mu_encoder[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating predictions on random images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "black_img = np.zeros(xte[1].shape)\n",
    "white_img = np.ones(xte[1].shape)\n",
    "random_img1 = np.random.rand(xte[1].shape[0], xte[1].shape[1], xte[1].shape[2])\n",
    "random_img2 = np.random.rand(xte[1].shape[0], xte[1].shape[1], xte[1].shape[2])\n",
    "random_img3 = np.random.rand(xte[1].shape[0], xte[1].shape[1], xte[1].shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cvae_best.full_model.predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cvae_best.decoder_model.predict(black_img.reshape([1,50,50,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_cvae_preds(img, cvae_model, n_samples=10):\n",
    "    x_vals = np.arange(0, 2*np.pi, 0.01)\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(7, 3))\n",
    "    axs[0].imshow(img)\n",
    "    axs[1].set_xticks(([0., .5*np.pi, np.pi, 1.5*np.pi, 2*np.pi]))\n",
    "    axs[1].set_xticklabels([\"$0$\", r\"$\\frac{\\pi}{2}$\", r\"$\\pi$\", r\"$\\frac{3\\pi}{2}$\", r\"$2\\pi$\"]) \n",
    "    axs[1].set_ylim([0, 2.0])\n",
    "    for i in range(0, n_samples):\n",
    "        preds = cvae_model.decoder_model.predict(img.reshape([1,50,50,3]))\n",
    "        mu_preds = np.deg2rad(bit2deg(preds[:, 0:2]))\n",
    "        kappa_preds = preds[:,2:]\n",
    "        axs[1].plot(x_vals, np.squeeze(vm_pdf(x_vals, mu_preds[0], kappa_preds[0]))) \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,5):\n",
    "    plot_cvae_preds(xte[i], cvaekl, 10)\n",
    "plot_cvae_preds(black_img, cvaekl, 10)\n",
    "plot_cvae_preds(white_img, cvaekl, 10)\n",
    "plot_cvae_preds(random_img1, cvaekl, 10)\n",
    "plot_cvae_preds(random_img2, cvaekl, 10)\n",
    "plot_cvae_preds(random_img3, cvaekl, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = cvae_best.full_model.evaluate([xte, yte_bit],yte_bit, verbose=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
