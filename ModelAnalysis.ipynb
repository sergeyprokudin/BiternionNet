{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Lambda, Flatten, Activation, Merge, Concatenate, Add\n",
    "from keras import layers\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Model, Sequential\n",
    "from keras.objectives import binary_crossentropy\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import sem\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "\n",
    "from models import vgg\n",
    "from models.cvae import CVAE\n",
    "from utils.angles import deg2bit, bit2deg\n",
    "from utils.losses import mad_loss_tf, cosine_loss_tf, von_mises_loss_tf, maad_from_deg\n",
    "from utils.losses import gaussian_kl_divergence_tf, gaussian_kl_divergence_np\n",
    "from utils.losses  import von_mises_log_likelihood_tf, von_mises_log_likelihood_np\n",
    "from utils.towncentre import load_towncentre\n",
    "from utils.experiements import get_experiment_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using canonical datasplit..\n"
     ]
    }
   ],
   "source": [
    "xtr, ytr_deg, xval, yval_deg, xte, yte_deg = load_towncentre('data/TownCentre.pkl.gz', canonical_split=True)\n",
    "\n",
    "image_height, image_width = xtr.shape[1], xtr.shape[2]\n",
    "ytr_bit = deg2bit(ytr_deg)\n",
    "yval_bit = deg2bit(yval_deg)\n",
    "yte_bit = deg2bit(yte_deg)\n",
    "\n",
    "image_height, image_width, n_channels = xtr.shape[1:]\n",
    "flatten_x_shape = xtr[0].flatten().shape[0]\n",
    "phi_shape = yte_bit.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 210.,  316.,  319., ...,  193.,  186.,  179.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytr_deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 151.,  145.,  150.,  153.,  142.,  177.,  293.,  283.,  132.,\n",
       "        144.,  176.,  138.,  143.,  341.,  347.,    7.,  173.,   36.,\n",
       "         32.,  340.,  176.,  349.,  345.,  186.,  173.,  177.,  180.,\n",
       "        180.,  180.,  175.,  167.,    0.,  329.,  312.,  140.,  147.,\n",
       "        147.,  324.,  330.,  347.,  233.,  133.,  127.,  326.,  316.,\n",
       "        173.,  161.,  170.,  149.,  158.,  329.,  321.,  347.,  302.,\n",
       "        117.,  287.,  295.,  299.,  136.,  129.,  171.,  141.,  199.,\n",
       "        353.,  347.,  346.,  353.,  160.,  349.,  355.,  145.,  152.,\n",
       "        163.,  173.,  175.,  297.,  300.,  302.,  299.,  104.,  119.,\n",
       "        123.,  152.,  156.,  314.,  164.,  146.,  125.,  207.,  181.,\n",
       "        152.,  143.,  152.,  343.,  338.,  153.,  154.,  148.,  176.,\n",
       "          3.,  332.,  334.,  356.,  341.,  314.,  320.,  320.,  318.,\n",
       "        343.,  338.,    7.,  349.,  353.,  347.,   53.,  294.,  327.,\n",
       "        350.,  145.,  139.,  136.,  142.,   37.,  356.,    9.,  154.,\n",
       "        148.,  328.,  326.,  332.,  336.,  156.,  142.,  155.,  304.,\n",
       "        308.,  297.,  308.,  276.,  151.,  161.,  134.,  144.,   26.,\n",
       "         35.,  260.,  279.,  272.,  171.,  354.,  340.,  142.,  222.,\n",
       "        310.,  342.,  338.,    0.,   58.,   67.,   77.,   10.,  340.,\n",
       "        285.,  103.,  314.,   32.,  326.,    4.,  152.,  165.,  174.,\n",
       "        167.,  170.,  168.,  174.,  168.,  315.,  315.,  208.,  201.,\n",
       "        144.,  146.,  153.,  153.,  335.,   52.,   14.,  335.,  348.,\n",
       "        298.,  295.,  165.,  161.,  348.,  156.,  189.,  174.,  174.,\n",
       "        176.,  200.,  274.,  344.,  352.,    6.,    0.,  180.,  178.,\n",
       "         11.,    9.,  346.,  343.,  339.,  343.,   59.,   41.,  304.,\n",
       "        276.,  321.,   36.,  305.,  308.,  321.,  311.,  304.,  314.,\n",
       "        326.,  319.,  311.,  355.,  151.,  162.,  203.,  206.,    8.,\n",
       "        317.,  316.,  175.,  148.,  162.,  171.,  337.,  346.,  295.,\n",
       "         36.,  288.,  217.,  155.,  288.,  292.,  287.,  281.,  152.,\n",
       "        184.,  255.,  241.,  234.,   23.,   25.,  320.,  247.,  239.,\n",
       "        346.,  316.,  303.,  174.,  166.,  155.,  137.,  168.,  167.,\n",
       "        175.,  250.,  288.,  300.,  307.,  321.,  320.,  317.,  133.,\n",
       "        209.,  143.,  181.,  181.,  227.,  224.,  289.,  297.,  330.,\n",
       "        353.,  319.,  300.,  156.,  185.,  118.,  168.,    0.,  155.,\n",
       "        159.,  191.,  146.,  146.,  123.,  117.,  126.,  307.,  298.,\n",
       "        303.,   72.,  137.,  171.,  169.,  148.,  169.,  326.,  300.,\n",
       "        287.,  268.,  333.,  323.,   34.,  313.,  143.,  266.,  139.,\n",
       "        140.,  139.,  152.,    5.,  172.,  167.,  151.,  278.,  314.,\n",
       "        292.,  276.,  159.,  313.,  130.,  133.,  135.,   94.,  105.,\n",
       "        126.,  284.,  320.,  309.,  315.,  267.,  104.,  113.,  159.,\n",
       "        206.,   93.,  104.,  111.,  320.,  324.,  175.,  173.,  142.,\n",
       "        304.,  309.,  348.,  338.,  301.,  346.,  347.,  337.,  184.,\n",
       "        177.,  154.,  178.,   52.,  298.,  341.,  289.,   65.,  150.,\n",
       "        121.,  325.,  334.,  318.,  170.,  139.,  112.,  141.,   99.,\n",
       "        143.,  177.,  170.,  161.,  181.,  270.,  264.,  264.,  262.,\n",
       "        298.,  320.,  331.,   29.,  315.,  176.,  327.,  230.,  310.,\n",
       "          7.,    0.,  184.,  176.,  175.,   35.,  247.,  305.,  318.,\n",
       "        271.,  267.,  162.,  163.,  164.,  355.,  353.,  353.,  341.,\n",
       "        345.,  332.,  113.,  184.,  174.,  179.,  175.,   70.,  155.,\n",
       "        156.,  164.,  181.,    2.,   16.,   48.,    6.,  125.,  165.,\n",
       "        125.,  200.,  175.,  169.,  129.,  133.,  133.,  141.,  281.,\n",
       "        318.,  306.,  316.,  337.,  353.,  353.,   16.,   44.,   54.,\n",
       "        347.,   35.,  324.,  132.,  132.,  106.,  134.,   23.,  174.,\n",
       "        174.,  141.,  162.,  164.,  106.,  110.,  308.,  179.,  170.,\n",
       "        168.,  174.,  169.,  174.,  184.,  128.,  135.,  343.,   10.,\n",
       "        310.,  338.,    7.,  209.,  215.,  210.,  207.,  218.,  183.,\n",
       "         67.,   77.,  228.,  216.,  184.,  222.,  217.,   19.,   13.,\n",
       "        353.,  187.,  324.,  328.,   20.,  184.,   11.,   15.,  174.,\n",
       "        187.,  183.,  180.,  180.,  180.,  185.,  193.,  360.,   31.,\n",
       "         48.,  220.,  213.,  213.,   36.,   30.,   13.,  127.,  227.,\n",
       "        233.,   34.,   44.,  187.,  199.,  190.,  211.,  202.,   31.,\n",
       "         39.,   13.,   58.,  243.,   73.,   65.,   61.,  224.,  231.,\n",
       "        189.,  219.,  161.,    7.,   13.,   14.,    7.,  200.,   11.,\n",
       "          5.,  215.,  208.,  197.,  187.,  185.,   63.,   60.,   58.,\n",
       "         61.,  256.,  241.,  237.,  208.,  204.,   46.,  196.,  214.,\n",
       "        235.,  153.,  179.,  208.,  217.,  208.,   17.,   22.,  207.,\n",
       "        206.,  212.,  184.,  357.,   28.,   26.,    4.,   19.,   46.,\n",
       "         40.,   40.,   42.,   17.,   22.,  353.,   11.,    7.,   13.,\n",
       "        307.,   66.,   33.,   10.,  215.,  221.,  224.,  218.,  323.,\n",
       "          4.,  351.,  206.,  212.,   32.,   34.,   28.,   24.,  204.,\n",
       "        218.,  205.,   56.,   52.,   63.,   52.,   84.,  209.,  199.,\n",
       "        226.,  216.,  334.,  325.,  100.,   81.,   88.,  189.,    6.,\n",
       "         20.,  218.,  138.,   50.,   18.,   22.,  360.,  302.,  293.,\n",
       "        283.,  350.,   20.,   75.,  257.,   46.,  328.,   34.,  356.,\n",
       "        208.,  195.,  186.,  193.,  190.,  192.,  186.,  192.,   45.,\n",
       "         45.,  152.,  159.,  216.,  214.,  207.,  207.,   25.,  308.,\n",
       "        346.,   25.,   12.,   62.,   65.,  195.,  199.,   12.,  204.,\n",
       "        171.,  186.,  186.,  184.,  160.,   86.,   16.,    8.,  354.,\n",
       "        360.,  180.,  182.,  349.,  351.,   14.,   17.,   21.,   17.,\n",
       "        301.,  319.,   56.,   84.,   39.,  324.,   55.,   52.,   39.,\n",
       "         49.,   56.,   46.,   34.,   41.,   49.,    5.,  209.,  198.,\n",
       "        157.,  154.,  352.,   43.,   44.,  185.,  212.,  198.,  189.,\n",
       "         23.,   14.,   65.,  324.,   72.,  143.,  205.,   72.,   68.,\n",
       "         73.,   79.,  208.,  176.,  105.,  119.,  126.,  337.,  335.,\n",
       "         40.,  113.,  121.,   14.,   44.,   57.,  186.,  194.,  205.,\n",
       "        223.,  192.,  193.,  185.,  110.,   72.,   60.,   53.,   39.,\n",
       "         40.,   43.,  227.,  151.,  217.,  179.,  179.,  133.,  136.,\n",
       "         71.,   63.,   30.,    7.,   41.,   60.,  204.,  175.,  242.,\n",
       "        192.,  360.,  205.,  201.,  169.,  214.,  214.,  237.,  243.,\n",
       "        234.,   53.,   62.,   57.,  288.,  223.,  189.,  191.,  212.,\n",
       "        191.,   34.,   60.,   73.,   92.,   27.,   37.,  326.,   47.,\n",
       "        217.,   94.,  221.,  220.,  221.,  208.,  355.,  188.,  193.,\n",
       "        209.,   82.,   46.,   68.,   84.,  201.,   47.,  230.,  227.,\n",
       "        225.,  266.,  255.,  234.,   76.,   40.,   51.,   45.,   93.,\n",
       "        256.,  247.,  201.,  154.,  267.,  256.,  249.,   40.,   36.,\n",
       "        185.,  187.,  218.,   56.,   51.,   12.,   22.,   59.,   14.,\n",
       "         13.,   23.,  176.,  183.,  206.,  182.,  308.,   62.,   19.,\n",
       "         71.,  295.,  210.,  239.,   35.,   26.,   42.,  190.,  221.,\n",
       "        248.,  219.,  261.,  217.,  183.,  190.,  199.,  179.,   90.,\n",
       "         96.,   96.,   98.,   62.,   40.,   29.,  331.,   45.,  184.,\n",
       "         33.,  130.,   50.,  353.,  360.,  176.,  184.,  185.,  325.,\n",
       "        113.,   55.,   42.,   89.,   93.,  198.,  197.,  196.,    5.,\n",
       "          7.,    7.,   19.,   15.,   28.,  247.,  176.,  186.,  181.,\n",
       "        185.,  290.,  205.,  204.,  196.,  179.,  358.,  344.,  312.,\n",
       "        354.,  235.,  195.,  235.,  160.,  185.,  191.,  231.,  227.,\n",
       "        227.,  219.,   79.,   42.,   54.,   44.,   23.,    7.,    7.,\n",
       "        344.,  316.,  306.,   13.,  325.,   36.,  228.,  228.,  254.,\n",
       "        226.,  337.,  186.,  186.,  219.,  198.,  196.,  254.,  250.,\n",
       "         52.,  181.,  190.,  192.,  186.,  191.,  186.,  176.,  232.,\n",
       "        225.,   17.,  350.,   50.,   22.,  353.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading pre-trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_fixed_kappa = vgg.BiternionVGG(image_height=image_height,\n",
    "                                   image_width=image_width,\n",
    "                                   n_channels=3,\n",
    "                                   predict_kappa=False,\n",
    "                                   fixed_kappa_value=3.0)\n",
    "\n",
    "vgg_fixed_kappa.model.load_weights('/Users/sergey/biternion_net_cluster_logs/vggbit_likelihood_learned_kappa_Adadelta_200epochs_batch10_89dd8240ed8b2175ad49/vgg_bit_vm_likelihood_town.best.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAAD error (train) : 71.467049 ± 57.111773\n",
      "log-likelihood (train) : -2.663717 ± 0.027228SEM\n",
      "MAAD error (validation) : 65.314157 ± 56.263639\n",
      "log-likelihood (validation) : -2.413951 ± 0.076771SEM\n",
      "MAAD error (test) : 67.156941 ± 56.452665\n",
      "log-likelihood (test) : -2.491740 ± 0.071362SEM\n"
     ]
    }
   ],
   "source": [
    "results = dict()\n",
    "results['train'] = vgg_fixed_kappa.evaluate(xtr, ytr_deg, 'train')\n",
    "results['validation'] = vgg_fixed_kappa.evaluate(xval, yval_deg, 'validation')\n",
    "results['test'] = vgg_fixed_kappa.evaluate(xte, yte_deg, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are trying to load a weight file containing 2 layers into a model with 3 layers.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-93e5cea11636>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                                      predict_kappa=True)\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mvgg_learned_kappa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/sergey/BiternionNet/logs/vggbit_likelihood_learned_kappa_Adadelta_200epochs_batch10_374f90e721d0fbc523ea/vgg_bit_vm_likelihood_town.best.weights.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/sergey/BiternionNet/py_env/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name)\u001b[0m\n\u001b[1;32m   2536\u001b[0m             \u001b[0mload_weights_from_hdf5_group_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2537\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2538\u001b[0;31m             \u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2540\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'close'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sergey/BiternionNet/py_env/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, layers)\u001b[0m\n\u001b[1;32m   2941\u001b[0m                          \u001b[0;34m'containing '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2942\u001b[0m                          \u001b[0;34m' layers into a model with '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2943\u001b[0;31m                          str(len(filtered_layers)) + ' layers.')\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m     \u001b[0;31m# We batch weight value assignments in a single backend call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: You are trying to load a weight file containing 2 layers into a model with 3 layers."
     ]
    }
   ],
   "source": [
    "vgg_learned_kappa = vgg.BiternionVGG(image_height=image_height,\n",
    "                                     image_width=image_width,\n",
    "                                     n_channels=3,\n",
    "                                     predict_kappa=True)\n",
    "\n",
    "vgg_learned_kappa.model.load_weights('/Users/sergey/BiternionNet/logs/vggbit_likelihood_learned_kappa_Adadelta_200epochs_batch10_374f90e721d0fbc523ea/vgg_bit_vm_likelihood_town.best.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAAD error (train) : 24.852653 ± 30.807507\n",
      "log-likelihood (train) : -0.745141 ± 0.012439SEM\n",
      "MAAD error (validation) : 25.865987 ± 34.247103\n",
      "log-likelihood (validation) : -0.731408 ± 0.036385SEM\n",
      "MAAD error (test) : 26.618819 ± 33.802968\n",
      "log-likelihood (test) : -0.744777 ± 0.033247SEM\n"
     ]
    }
   ],
   "source": [
    "learned_tr_res = eval_bvgg_model(vgg_learned_kappa, xtr, ytr_deg, ytr_bit, 'train')\n",
    "learned_val_res = eval_bvgg_model(vgg_learned_kappa, xval, yval_deg, yval_bit, 'validation')\n",
    "learned_te_res = eval_bvgg_model(vgg_learned_kappa, xte, yte_deg, yte_bit, 'test')\n",
    "learned_te_preds_bit = vgg_fixed_kappa.model.predict(xte)\n",
    "learned_te_preds_deg = bit2deg(learned_te_preds_bit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg_cosine = vgg.BiternionVGG(image_height=image_height,\n",
    "                              image_width=image_width,\n",
    "                              n_channels=3,\n",
    "                              predict_kappa=False)\n",
    "\n",
    "vgg_cosine.model.load_weights('logs/best_models/cosine/vgg_bit_cosine_town.final_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAAD error (train) : 13.700977 ± 17.924503\n",
      "predicted kappa (train) : 1.000000 ± 0.000000\n",
      "log-likelihood (train) : -1.135066 ± 0.002367SEM\n",
      "MAAD error (validation) : 14.782664 ± 19.419558\n",
      "predicted kappa (validation) : 1.000000 ± 0.000000\n",
      "log-likelihood (validation) : -1.145701 ± 0.007528SEM\n",
      "MAAD error (test) : 15.520041 ± 22.154984\n",
      "predicted kappa (test) : 1.000000 ± 0.000000\n",
      "log-likelihood (test) : -1.154747 ± 0.008343SEM\n"
     ]
    }
   ],
   "source": [
    "cosine_tr_res = eval_bvgg_model(vgg_cosine, xtr, ytr_deg, ytr_bit, 'train')\n",
    "cosine_val_res = eval_bvgg_model(vgg_cosine, xval, yval_deg, yval_bit, 'validation')\n",
    "cosine_te_res = eval_bvgg_model(vgg_cosine, xte, yte_deg, yte_bit, 'test')\n",
    "learned_te_preds_bit = vgg_cosine.model.predict(xte)\n",
    "learned_te_preds_deg = bit2deg(fixed_te_preds_bit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg_vm = vgg.BiternionVGG(image_height=image_height,\n",
    "                          image_width=image_width,\n",
    "                          n_channels=3,\n",
    "                          predict_kappa=False)\n",
    "\n",
    "vgg_vm.model.load_weights('logs/best_models/von_mises/vgg_bit_von_mises_town.best.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAAD error (train) : 16.481105 ± 22.488998\n",
      "predicted kappa (train) : 1.000000 ± 0.000000\n",
      "log-likelihood (train) : -1.162347 ± 0.003133SEM\n",
      "MAAD error (validation) : 17.421278 ± 25.500195\n",
      "predicted kappa (validation) : 1.000000 ± 0.000000\n",
      "log-likelihood (validation) : -1.176983 ± 0.010404SEM\n",
      "MAAD error (test) : 16.819883 ± 23.218121\n",
      "predicted kappa (test) : 1.000000 ± 0.000000\n",
      "log-likelihood (test) : -1.163565 ± 0.008568SEM\n"
     ]
    }
   ],
   "source": [
    "vm_tr_res = eval_bvgg_model(vgg_vm, xtr, ytr_deg, ytr_bit, 'train')\n",
    "vm_val_res = eval_bvgg_model(vgg_vm, xval, yval_deg, yval_bit, 'validation')\n",
    "vm_te_res = eval_bvgg_model(vgg_vm, xte, yte_deg, yte_bit, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CVAE model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_u = 8\n",
    "cvae_best = CVAE(n_hidden_units=n_u)\n",
    "cvae_ckpt_path = 'logs/cvae.full_model.weights.hdf5'\n",
    "cvae_best.full_model.load_weights(cvae_ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_cvae_model(cvae_model, x, ytrue_deg, ytrue_bit, data_part):\n",
    "    \n",
    "    n_samples = x.shape[0]\n",
    "\n",
    "    cvae_preds = cvae_model.full_model.predict([x, ytrue_bit])\n",
    "    elbo_te, ll_te, kl_te = cvae_model._cvae_elbo_loss_np(ytrue_bit, cvae_preds)\n",
    "\n",
    "    ypreds = cvae_model.decoder_model.predict(x)\n",
    "    ypreds_bit = ypreds[:,0:2]\n",
    "    kappa_preds_te = ypreds[:,2:]\n",
    "\n",
    "    ypreds_deg = bit2deg(ypreds_bit)\n",
    "\n",
    "    loss_te = maad_from_deg(ytrue_deg, ypreds_deg)\n",
    "    mean_loss_te = np.mean(loss_te)\n",
    "    std_loss_te = np.std(loss_te)\n",
    "\n",
    "    print(\"MAAD error (%s) : %f ± %f\" % (data_part, mean_loss_te, std_loss_te))\n",
    "\n",
    "    # print(\"kappa (%s) : %f ± %f\" % (data_part, np.mean(kappa_preds_te), np.std(kappa_preds_te)))\n",
    "\n",
    "    log_likelihood_loss = von_mises_log_likelihood_np(ytrue_bit, ypreds_bit, kappa_preds_te,\n",
    "                                                         input_type='biternion')\n",
    "\n",
    "    # print(\"ELBO (%s) : %f ± %f SEM\" % (data_part, np.mean(-elbo_te), sem(-elbo_te)))\n",
    "\n",
    "    #print(\"KL(encoder|prior) (%s) : %f ± %f SEM\" % (data_part, np.mean(-kl_te), sem(-kl_te)))\n",
    "\n",
    "    print(\"log-likelihood (%s) : %f±%fSEM\" % (data_part, \n",
    "                                              np.mean(log_likelihood_loss), \n",
    "                                              sem(log_likelihood_loss)))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAAD error (train) : 24.147247 ± 31.294075\n",
      "log-likelihood (train) : -0.689477±0.054274SEM\n",
      "MAAD error (validation) : 23.855638 ± 32.482711\n",
      "log-likelihood (validation) : -0.652637±0.058809SEM\n",
      "MAAD error (test) : 24.191327 ± 31.100941\n",
      "log-likelihood (test) : -0.691666±0.054426SEM\n"
     ]
    }
   ],
   "source": [
    "eval_cvae_model(cvae_best, xte, yte_deg, yte_bit, 'train')\n",
    "eval_cvae_model(cvae_best, xval, yval_deg, yval_bit, 'validation')\n",
    "eval_cvae_model(cvae_best, xte, yte_deg, yte_bit, 'test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
