{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Lambda, Flatten, Activation, Merge, Concatenate, Add\n",
    "from keras import layers\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Model, Sequential\n",
    "from keras.objectives import binary_crossentropy\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import sem\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from models import vgg\n",
    "from models.cvae import CVAE\n",
    "from models.cvae_mod import CVAE as CVAE_mod\n",
    "from utils.losses import von_mises_log_likelihood_np\n",
    "from utils.angles import deg2bit, bit2deg, bit2deg_multi\n",
    "from utils.losses import mad_loss_tf, cosine_loss_tf, von_mises_loss_tf, maad_from_deg\n",
    "from utils.losses import gaussian_kl_divergence_tf, gaussian_kl_divergence_np\n",
    "from utils.losses import gaussian_log_likelihood_np, gaussian_log_likelihood_scipy, gaussian_log_likelihood_tf\n",
    "from utils.losses  import von_mises_log_likelihood_tf, von_mises_log_likelihood_np\n",
    "from utils.losses import maximum_expected_utility\n",
    "from utils.towncentre import load_towncentre, aug_data\n",
    "from utils.experiements import get_experiment_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train samples: 6916\n",
      "Number of validation samples: 874\n",
      "Number of test samples: 904\n"
     ]
    }
   ],
   "source": [
    "xtr, ytr_deg, xval, yval_deg, xte, yte_deg = load_towncentre('data/TownCentre.pkl.gz', canonical_split=True, verbose=1)\n",
    "\n",
    "image_height, image_width = xtr.shape[1], xtr.shape[2]\n",
    "\n",
    "ytr_bit = deg2bit(ytr_deg)\n",
    "yval_bit = deg2bit(yval_deg)\n",
    "yte_bit = deg2bit(yte_deg)\n",
    "yte_rad = np.deg2rad(yte_deg)\n",
    "\n",
    "image_height, image_width, n_channels = xtr.shape[1:]\n",
    "flatten_x_shape = xtr[0].flatten().shape[0]\n",
    "phi_shape = yte_bit.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading pre-trained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Biternion-VGG (cosine-loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAAD error (train) : 6.394312 ± 0.073692SEM\n",
      "log-likelihood (train) : -0.456771 ± 0.001295SEM\n",
      "MAAD error (validation) : 21.833931 ± 0.966800SEM\n",
      "log-likelihood (validation) : -0.843196 ± 0.034713SEM\n",
      "MAAD error (test) : 24.108348 ± 1.069605SEM\n",
      "log-likelihood (test) : -0.926001 ± 0.038936SEM\n"
     ]
    }
   ],
   "source": [
    "vgg_cosine = vgg.BiternionVGG(image_height=image_height,\n",
    "                              image_width=image_width,\n",
    "                              n_channels=3,\n",
    "                              predict_kappa=False,\n",
    "                              fixed_kappa_value=3.0)\n",
    "\n",
    "vgg_cosine.model.load_weights('../biternion_net_cluster_logs/best_models/cosine/vgg_bit_cosine_town.best.weights.h5')\n",
    "\n",
    "results_cosine = dict()\n",
    "results_cosine['train'] = vgg_cosine.evaluate(xtr, ytr_deg, 'train')\n",
    "results_cosine['validation'] = vgg_cosine.evaluate(xval, yval_deg, 'validation')\n",
    "results_cosine['test'] = vgg_cosine.evaluate(xte, yte_deg, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Biternion-VGG (Von-Mises loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAAD error (train) : 9.459415 ± 0.142856SEM\n",
      "log-likelihood (train) : -0.510601 ± 0.004218SEM\n",
      "MAAD error (validation) : 22.974047 ± 0.999363SEM\n",
      "log-likelihood (validation) : -0.883493 ± 0.036697SEM\n",
      "MAAD error (test) : 24.156092 ± 1.083819SEM\n",
      "log-likelihood (test) : -0.925846 ± 0.039583SEM\n"
     ]
    }
   ],
   "source": [
    "vgg_vm = vgg.BiternionVGG(image_height=image_height,\n",
    "                          image_width=image_width,\n",
    "                          n_channels=3,\n",
    "                          predict_kappa=False,\n",
    "                          fixed_kappa_value=3.0)\n",
    "\n",
    "vgg_vm.model.load_weights('../biternion_net_cluster_logs/best_models/von_mises/vgg_bit_von_mises_town.best.weights.h5')\n",
    "\n",
    "results_vm = dict()\n",
    "results_vm['train'] = vgg_vm.evaluate(xtr, ytr_deg, 'train')\n",
    "results_vm['validation'] = vgg_vm.evaluate(xval, yval_deg, 'validation')\n",
    "results_vm['test'] = vgg_vm.evaluate(xte, yte_deg, 'test')\n",
    "\n",
    "vm_preds = vgg_vm.model.predict(xte)\n",
    "vm_preds_mu_rad = np.deg2rad(bit2deg(vm_preds))\n",
    "vm_preds_kappa = np.ones([xte.shape[0],1])*3\n",
    "vm_preds_likelihoods = von_mises_log_likelihood_np(yte_bit, vm_preds[:,0:2], vm_preds_kappa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Biternion-VGG (log-likelihood, fixed  $\\kappa=3$ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAAD error (train) : 11.216375 ± 0.144446SEM\n",
      "log-likelihood (train) : -0.533973 ± 0.003843SEM\n",
      "MAAD error (validation) : 22.728342 ± 0.990586SEM\n",
      "log-likelihood (validation) : -0.870462 ± 0.035802SEM\n",
      "MAAD error (test) : 24.155143 ± 1.088582SEM\n",
      "log-likelihood (test) : -0.929270 ± 0.039672SEM\n"
     ]
    }
   ],
   "source": [
    "vgg_fixed_kappa = vgg.BiternionVGG(image_height=image_height,\n",
    "                                   image_width=image_width,\n",
    "                                   n_channels=3,\n",
    "                                   predict_kappa=False,\n",
    "                                   fixed_kappa_value=3.0)\n",
    "\n",
    "vgg_fixed_kappa.model.load_weights('../biternion_net_cluster_logs/best_models/fixed_kappa/vgg_bit_vm_likelihood_town.best.weights.h5')\n",
    "\n",
    "results_fixed = dict()\n",
    "results_fixed['train'] = vgg_fixed_kappa.evaluate(xtr, ytr_deg, 'train')\n",
    "results_fixed['validation'] = vgg_fixed_kappa.evaluate(xval, yval_deg, 'validation')\n",
    "results_fixed['test'] = vgg_fixed_kappa.evaluate(xte, yte_deg, 'test')\n",
    "\n",
    "fixed_preds = vgg_fixed_kappa.model.predict(xte)\n",
    "fixed_preds_mu_rad = np.deg2rad(bit2deg(fixed_preds))\n",
    "fixed_preds_kappa = np.ones([xte.shape[0],1])*3\n",
    "fixed_preds_likelihoods = von_mises_log_likelihood_np(yte_bit, fixed_preds[:,0:2], fixed_preds_kappa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Biternion-VGG (log-likelihood loss, learned  $\\kappa$ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAAD error (train) : 14.462390 ± 0.213100SEM\n",
      "log-likelihood (train) : -0.203715 ± 0.010644SEM\n",
      "MAAD error (validation) : 24.398405 ± 1.090128SEM\n",
      "log-likelihood (validation) : -0.802889 ± 0.078568SEM\n",
      "MAAD error (test) : 24.327137 ± 1.095842SEM\n",
      "log-likelihood (test) : -0.764323 ± 0.066594SEM\n"
     ]
    }
   ],
   "source": [
    "vgg_learned_kappa = vgg.BiternionVGG(image_height=image_height,\n",
    "                                     image_width=image_width,\n",
    "                                     n_channels=3,\n",
    "                                     predict_kappa=True)\n",
    "\n",
    "vgg_learned_kappa.model.load_weights('../biternion_net_cluster_logs/best_models/learned_kappa/vgg_bit_vm_likelihood_town.best.weights.h5')\n",
    "\n",
    "results_learned = dict()\n",
    "results_learned['train'] = vgg_learned_kappa.evaluate(xtr, ytr_deg, 'train')\n",
    "results_learned['validation'] = vgg_learned_kappa.evaluate(xval, yval_deg, 'validation')\n",
    "results_learned['test'] = vgg_learned_kappa.evaluate(xte, yte_deg, 'test')\n",
    "\n",
    "learned_preds = vgg_learned_kappa.model.predict(xte)\n",
    "learned_preds_mu_rad = np.deg2rad(bit2deg(learned_preds[:,0:2]))\n",
    "learned_preds_kappa = learned_preds[:,2:]\n",
    "learned_preds_likelihoods = von_mises_log_likelihood_np(yte_bit, learned_preds[:,0:2], learned_preds_kappa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CVAE model (normal training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAAD error (train) : 14.758449 ± 0.220159SEM\n",
      "ELBO (train) : -0.201158 ± 0.008586SEM\n",
      "KL-div (train) : 0.000010 ± 0.000002SEM\n",
      "MAAD error (validation) : 23.260531 ± 1.041506SEM\n",
      "ELBO (validation) : -0.608598 ± 0.041171SEM\n",
      "KL-div (validation) : 0.000040 ± 0.000027SEM\n",
      "MAAD error (test) : 26.120249 ± 1.185110SEM\n",
      "ELBO (test) : -0.667623 ± 0.047162SEM\n",
      "KL-div (test) : 0.000013 ± 0.000003SEM\n"
     ]
    }
   ],
   "source": [
    "n_samples = 10\n",
    "n_u = 8\n",
    "cvae = CVAE(n_hidden_units=n_u)\n",
    "cvae_ckpt_path = '../biternion_net_cluster_logs/best_models/cvae/original_trainining/cvae.full_model.trial_4.best.weights.hdf5'\n",
    "cvae.full_model.load_weights(cvae_ckpt_path)\n",
    "\n",
    "results_cvae = dict()\n",
    "results_cvae['train'] = cvae.evaluate(xtr, ytr_deg, 'train')\n",
    "results_cvae['validation'] = cvae.evaluate(xval, yval_deg, 'validation')\n",
    "results_cvae['test'] = cvae.evaluate(xte, yte_deg, 'test')\n",
    "\n",
    "cvae_preds = cvae.get_multiple_predictions(xte, yte_bit, n_samples=n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_multiple_predictions(self, x, y_bit, n_samples=5):\n",
    "\n",
    "        n_points = x.shape[0]\n",
    "\n",
    "        mu_bit_preds = np.zeros([n_points, n_samples, 2])\n",
    "        kappa_preds  = np.zeros([n_points, n_samples, 1])\n",
    "        reconstruction_errs = np.zeros([n_points, n_samples, 1])\n",
    "        kl_preds = np.zeros([n_points, n_samples, 1])\n",
    "        elbo_preds = np.zeros([n_points, n_samples, 1])\n",
    "        u_encoder = np.zeros([n_points, n_samples, self.n_u])\n",
    "\n",
    "        mu_bit_preds_dec = np.zeros([n_points, n_samples, 2])\n",
    "        kappa_preds_dec = np.zeros([n_points, n_samples, 1])\n",
    "\n",
    "        for sid in range(0, n_samples):\n",
    "            preds = self.full_model.predict([x, y_bit])\n",
    "            mu_bit_preds[:, sid, :] = preds[:, self.n_u * 5:self.n_u * 5 + 2]\n",
    "            u_encoder[:, sid, :] = preds[:, self.n_u*4:self.n_u*5]\n",
    "            kappa_preds[:, sid, :] = preds[:, self.n_u * 5 + 2:].reshape(-1, 1)\n",
    "            elbo, reconstruction, kl = self._cvae_elbo_loss_np(y_bit, preds)\n",
    "            reconstruction_errs[:, sid, :] = reconstruction\n",
    "            kl_preds[:, sid, :] = kl\n",
    "            elbo_preds[:, sid, :] = elbo\n",
    "            preds_dec = self.decoder_model.predict(x, batch_size=100)\n",
    "            mu_bit_preds_dec[:, sid, :] = preds_dec[:, 0:2]\n",
    "            kappa_preds_dec[:, sid, :] = preds_dec[:, 2:].reshape(-1, 1)\n",
    "\n",
    "        preds = dict()\n",
    "\n",
    "        preds['mu_bit'] = mu_bit_preds\n",
    "        preds['kappa'] = kappa_preds\n",
    "        preds['u_encoder'] = u_encoder\n",
    "        preds['reconstruction_err'] = reconstruction_errs\n",
    "        preds['kl_div'] = kl_preds\n",
    "        preds['elbo'] = elbo_preds\n",
    "        preds['mu_bit_dec'] = mu_bit_preds_dec\n",
    "        preds['kappa_dec'] = kappa_preds_dec\n",
    "        preds['mu_rad_dec'] = np.deg2rad(bit2deg_multi(preds['mu_bit_dec']))\n",
    "        preds['maxutil_deg_dec'] = maximum_expected_utility(np.rad2deg(preds['mu_rad_dec']))\n",
    "\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvae_preds = get_multiple_predictions(cvae, xte, yte_bit, n_samples=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.2714293 ,  0.67456287, -0.63676488,  0.04904794, -1.6937753 ,\n",
       "        -0.44603804, -0.06594743, -0.60049832],\n",
       "       [ 1.59189463, -0.03547023, -0.65295184, -0.13376227,  0.99077588,\n",
       "        -0.59087682,  0.74417186, -0.25710058]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvae_preds['u_encoder'][0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CVAE model (KL annealing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAAD error (test) : 25.375051 ± 1.176808SEM\n",
      "ELBO (test) : -0.729948 ± 0.056895SEM\n",
      "KL-div (test) : 0.206518 ± 0.015021SEM\n"
     ]
    }
   ],
   "source": [
    "n_u = 8\n",
    "cvaekl = CVAE(n_hidden_units=n_u)\n",
    "cvaekl_ckpt_path = '../biternion_net_cluster_logs/best_models/cvae/kl_annealing/cvae.full_model.trial_1.best.weights.hdf5'\n",
    "cvaekl.full_model.load_weights(cvaekl_ckpt_path)\n",
    "\n",
    "results_cvaekl = dict()\n",
    "results_cvaekl['train'] = evaluate_multi(xtr, ytr_deg, 'train')\n",
    "results_cvaekl['validation'] = evaluate_multi(cvaekl, xval, yval_deg, 'validation', n_samples=n_samples)\n",
    "results_cvaekl['test'] = evaluate_multi(cvaekl, xte, yte_deg, 'test', n_samples=n_samples)\n",
    "\n",
    "#cvaekl_mu_bit_preds, cvaekl_kappa_preds = cvaekl.generate_multiple_samples(xte)\n",
    "cvaekl_preds = cvaekl.get_multiple_predictions(xte, yte_bit, n_samples=n_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CVAE model (augmentation with opposite angles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAAD error (train) : 89.978635 ± 0.551583SEM\n",
      "ELBO (train) : -3.587595 ± 0.024828SEM\n",
      "KL-div (train) : 0.000981 ± 0.000025SEM\n",
      "MAAD error (validation) : 90.165400 ± 1.516843SEM\n",
      "ELBO (validation) : -3.490701 ± 0.066569SEM\n",
      "KL-div (validation) : 0.001268 ± 0.000082SEM\n",
      "MAAD error (test) : 89.923780 ± 1.491162SEM\n",
      "ELBO (test) : -3.530247 ± 0.066768SEM\n",
      "KL-div (test) : 0.001393 ± 0.000093SEM\n"
     ]
    }
   ],
   "source": [
    "n_u = 8\n",
    "cvaeaug = CVAE(n_hidden_units=n_u)\n",
    "cvaeaug_ckpt_path = '../biternion_net_cluster_logs/best_models/cvae/opposite_labels_aug/cvae.full_model.trial_0.best.weights.hdf5'\n",
    "cvaeaug.full_model.load_weights(cvaeaug_ckpt_path)\n",
    "\n",
    "xtr_aug, ytr_aug_deg = aug_data(xtr, ytr_deg)\n",
    "xval_aug, yval_aug_deg = aug_data(xval, yval_deg)\n",
    "xte_aug, yte_aug_deg = aug_data(xte, yte_deg)\n",
    "ytr_aug_bit = deg2bit(ytr_aug_deg)\n",
    "yval_aug_bit = deg2bit(yval_aug_deg)\n",
    "yte_aug_bit = deg2bit(yte_aug_deg)\n",
    "\n",
    "results_cvaeaug = dict()\n",
    "results_cvaeaug['train'] = cvaeaug.evaluate(xtr_aug, ytr_aug_deg, 'train')\n",
    "results_cvaeaug['validation'] = cvaeaug.evaluate(xval_aug, yval_aug_deg, 'validation')\n",
    "results_cvaeaug['test'] = cvaeaug.evaluate(xte_aug, yte_aug_deg, 'test')\n",
    "\n",
    "cvaeaug_preds = cvaekl.get_multiple_predictions(xte, yte_bit, n_samples=n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.losses import log_bessel_approx_np\n",
    "\n",
    "def vm_pdf(vals, mu_rad, kappa):\n",
    "    return np.exp(kappa * np.cos(vals-mu_rad)) / (2* np.pi * np.exp(log_bessel_approx_np(kappa)))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def plot_vm_dists(fid):\n",
    "    x_vals = np.arange(0, 2*np.pi, 0.01)\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 7, figsize=(25, 5))\n",
    "    \n",
    "    axs[0].imshow(xte[fid])\n",
    "    \n",
    "    def _plt_vgg(axis, mu_rad_preds, kappa_preds, log_likelihoods, method_name):\n",
    "        axis.set_xticks(([0., .5*np.pi, np.pi, 1.5*np.pi, 2*np.pi]))\n",
    "        axis.set_xticklabels([\"$0$\", r\"$\\frac{\\pi}{2}$\", r\"$\\pi$\", r\"$\\frac{3\\pi}{2}$\", r\"$2\\pi$\"]) \n",
    "        axis.set_xlim([-0.001, 2*np.pi+0.001])\n",
    "        axis.plot(x_vals, np.squeeze(vm_pdf(x_vals, mu_rad_preds[fid], kappa_preds[fid])))\n",
    "        axis.axvline(yte_rad[fid], color='red')\n",
    "        axis.set_title(\"%s (logL=%.2f)\" % (method_name, log_likelihoods[fid]))\n",
    "        axis.set_ylim([0, 2.0])\n",
    "        \n",
    "    def _plt_cvae(axis, cvae_mu_rad_preds, cvae_kappa_preds, method_name, plot_mixture=False):\n",
    "        axis.set_xticks(([0., .5*np.pi, np.pi, 1.5*np.pi, 2*np.pi]))\n",
    "        axis.set_xticklabels([\"$0$\", r\"$\\frac{\\pi}{2}$\", r\"$\\pi$\", r\"$\\frac{3\\pi}{2}$\", r\"$2\\pi$\"]) \n",
    "        axis.set_xlim([-0.001, 2*np.pi+0.001])\n",
    "        vm_vals = np.zeros([n_samples, x_vals.shape[0]])\n",
    "        if plot_mixture:\n",
    "            for sid in range(0, n_samples):\n",
    "                vm_vals[sid, :] = vm_pdf(x_vals, cvae_mu_rad_preds[fid, sid], cvae_kappa_preds[fid, sid])\n",
    "            axis.plot(x_vals, np.mean(vm_vals, axis=0))\n",
    "        else:\n",
    "            for sid in range(0, n_samples):\n",
    "                axis.plot(x_vals, np.squeeze(vm_pdf(x_vals, cvae_mu_rad_preds[fid, sid], cvae_kappa_preds[fid, sid])))  \n",
    "        axis.axvline(yte_rad[fid], color='red')\n",
    "        axis.set_title(\"%s \" % method_name)\n",
    "        axis.set_ylim([0, 2.0])\n",
    "        \n",
    "    _plt_vgg(axs[1], vm_preds_mu_rad, vm_preds_kappa, vm_preds_likelihoods, 'original (Von-Mises loss)')\n",
    "    _plt_vgg(axs[2], fixed_preds_mu_rad, fixed_preds_kappa, fixed_preds_likelihoods,  'fixed kappa')\n",
    "    _plt_vgg(axs[3], learned_preds_mu_rad, learned_preds_kappa, learned_preds_likelihoods, 'learned kappa')\n",
    "    _plt_cvae(axs[4], cvae_preds['mu_rad_dec'], cvae_preds['kappa_dec'], \"CVAE (normal)\")\n",
    "    _plt_cvae(axs[5], cvaekl_mu_rad_preds,  cvaekl_kappa_preds, \"CVAE (KL annealing)\")\n",
    "    _plt_cvae(axs[6], cvaekl_mu_rad_preds, cvaekl_kappa_preds, \"CVAE (KL annealing, mixture density)\", plot_mixture=True)\n",
    "    # _plt_cvae(axs[7], cvaeaug_mu_rad_preds,  cvaeaug_kappa_preds, \"CVAE (Random labels augmentation)\")\n",
    "    # _plt_cvae(axs[8], cvaeaug_mu_rad_preds, cvaeaug_kappa_preds, \"CVAE (Random labels augmentation, mixture density)\", plot_mixture=True)\n",
    "    fig.suptitle(\"frame id =%d\" %fid)\n",
    "    #plt.plot((ytr_deg, x2), (y1, y2), 'k-')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_vm_dists' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-645ef730bad8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mplot_vm_dists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_vm_dists' is not defined"
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "n_samples = 10\n",
    "\n",
    "for fid in range(0, 10):\n",
    "    plot_vm_dists(fid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
