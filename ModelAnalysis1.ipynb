{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Lambda, Flatten, Activation, Merge, Concatenate, Add\n",
    "from keras import layers\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Model, Sequential\n",
    "from keras.objectives import binary_crossentropy\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import sem\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from models import vgg\n",
    "from models.cvae import CVAE\n",
    "from models.cvae_mod import CVAE as CVAE_mod\n",
    "from utils.losses import von_mises_log_likelihood_np\n",
    "from utils.angles import deg2bit, bit2deg, bit2deg_multi\n",
    "from utils.losses import mad_loss_tf, cosine_loss_tf, von_mises_loss_tf, maad_from_deg\n",
    "from utils.losses import gaussian_kl_divergence_tf, gaussian_kl_divergence_np\n",
    "from utils.losses import gaussian_log_likelihood_np, gaussian_log_likelihood_scipy, gaussian_log_likelihood_tf\n",
    "from utils.losses  import von_mises_log_likelihood_tf, von_mises_log_likelihood_np\n",
    "from utils.losses import maximum_expected_utility, importance_loglikelihood\n",
    "from utils.towncentre import load_towncentre, aug_data\n",
    "from utils.experiements import get_experiment_id\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train samples: 6916\n",
      "Number of validation samples: 874\n",
      "Number of test samples: 904\n"
     ]
    }
   ],
   "source": [
    "xtr, ytr_deg, xval, yval_deg, xte, yte_deg = load_towncentre('data/TownCentre.pkl.gz', canonical_split=True, verbose=1)\n",
    "\n",
    "image_height, image_width = xtr.shape[1], xtr.shape[2]\n",
    "\n",
    "ytr_bit = deg2bit(ytr_deg)\n",
    "yval_bit = deg2bit(yval_deg)\n",
    "yte_bit = deg2bit(yte_deg)\n",
    "yte_rad = np.deg2rad(yte_deg)\n",
    "\n",
    "image_height, image_width, n_channels = xtr.shape[1:]\n",
    "flatten_x_shape = xtr[0].flatten().shape[0]\n",
    "phi_shape = yte_bit.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading pre-trained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Biternion-VGG (cosine-loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAAD error (train) : 6.394312 ± 0.073692SEM\n",
      "log-likelihood (train) : -0.456771 ± 0.001295SEM\n",
      "MAAD error (validation) : 21.833931 ± 0.966800SEM\n",
      "log-likelihood (validation) : -0.843196 ± 0.034713SEM\n",
      "MAAD error (test) : 24.108348 ± 1.069605SEM\n",
      "log-likelihood (test) : -0.926001 ± 0.038936SEM\n"
     ]
    }
   ],
   "source": [
    "vgg_cosine = vgg.BiternionVGG(image_height=image_height,\n",
    "                              image_width=image_width,\n",
    "                              n_channels=3,\n",
    "                              predict_kappa=False,\n",
    "                              fixed_kappa_value=3.0)\n",
    "\n",
    "vgg_cosine.model.load_weights('../biternion_net_cluster_logs/best_models/cosine/vgg_bit_cosine_town.best.weights.h5')\n",
    "\n",
    "results_cosine = dict()\n",
    "results_cosine['train'] = vgg_cosine.evaluate(xtr, ytr_deg, 'train')\n",
    "results_cosine['validation'] = vgg_cosine.evaluate(xval, yval_deg, 'validation')\n",
    "results_cosine['test'] = vgg_cosine.evaluate(xte, yte_deg, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Biternion-VGG (Von-Mises loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAAD error (train) : 9.459415 ± 0.142856SEM\n",
      "log-likelihood (train) : -0.510601 ± 0.004218SEM\n",
      "MAAD error (validation) : 22.974047 ± 0.999363SEM\n",
      "log-likelihood (validation) : -0.883493 ± 0.036697SEM\n",
      "MAAD error (test) : 24.156092 ± 1.083819SEM\n",
      "log-likelihood (test) : -0.925846 ± 0.039583SEM\n"
     ]
    }
   ],
   "source": [
    "vgg_vm = vgg.BiternionVGG(image_height=image_height,\n",
    "                          image_width=image_width,\n",
    "                          n_channels=3,\n",
    "                          predict_kappa=False,\n",
    "                          fixed_kappa_value=3.0)\n",
    "\n",
    "vgg_vm.model.load_weights('../biternion_net_cluster_logs/best_models/von_mises/vgg_bit_von_mises_town.best.weights.h5')\n",
    "\n",
    "results_vm = dict()\n",
    "results_vm['train'] = vgg_vm.evaluate(xtr, ytr_deg, 'train')\n",
    "results_vm['validation'] = vgg_vm.evaluate(xval, yval_deg, 'validation')\n",
    "results_vm['test'] = vgg_vm.evaluate(xte, yte_deg, 'test')\n",
    "\n",
    "vm_preds = vgg_vm.model.predict(xte)\n",
    "vm_preds_mu_rad = np.deg2rad(bit2deg(vm_preds))\n",
    "vm_preds_kappa = np.ones([xte.shape[0],1])*3\n",
    "vm_preds_likelihoods = von_mises_log_likelihood_np(yte_bit, vm_preds[:,0:2], vm_preds_kappa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Biternion-VGG (log-likelihood, fixed  $\\kappa=3$ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAAD error (train) : 11.216375 ± 0.144446SEM\n",
      "log-likelihood (train) : -0.533973 ± 0.003843SEM\n",
      "MAAD error (validation) : 22.728342 ± 0.990586SEM\n",
      "log-likelihood (validation) : -0.870462 ± 0.035802SEM\n",
      "MAAD error (test) : 24.155143 ± 1.088582SEM\n",
      "log-likelihood (test) : -0.929270 ± 0.039672SEM\n"
     ]
    }
   ],
   "source": [
    "vgg_fixed_kappa = vgg.BiternionVGG(image_height=image_height,\n",
    "                                   image_width=image_width,\n",
    "                                   n_channels=3,\n",
    "                                   predict_kappa=False,\n",
    "                                   fixed_kappa_value=3.0)\n",
    "\n",
    "vgg_fixed_kappa.model.load_weights('../biternion_net_cluster_logs/best_models/fixed_kappa/vgg_bit_vm_likelihood_town.best.weights.h5')\n",
    "\n",
    "results_fixed = dict()\n",
    "results_fixed['train'] = vgg_fixed_kappa.evaluate(xtr, ytr_deg, 'train')\n",
    "results_fixed['validation'] = vgg_fixed_kappa.evaluate(xval, yval_deg, 'validation')\n",
    "results_fixed['test'] = vgg_fixed_kappa.evaluate(xte, yte_deg, 'test')\n",
    "\n",
    "fixed_preds = vgg_fixed_kappa.model.predict(xte)\n",
    "fixed_preds_mu_rad = np.deg2rad(bit2deg(fixed_preds))\n",
    "fixed_preds_kappa = np.ones([xte.shape[0],1])*3\n",
    "fixed_preds_likelihoods = von_mises_log_likelihood_np(yte_bit, fixed_preds[:,0:2], fixed_preds_kappa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Biternion-VGG (log-likelihood loss, learned  $\\kappa$ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAAD error (train) : 14.462390 ± 0.213100SEM\n",
      "log-likelihood (train) : -0.203715 ± 0.010644SEM\n",
      "MAAD error (validation) : 24.398405 ± 1.090128SEM\n",
      "log-likelihood (validation) : -0.802889 ± 0.078568SEM\n",
      "MAAD error (test) : 24.327137 ± 1.095842SEM\n",
      "log-likelihood (test) : -0.764323 ± 0.066594SEM\n"
     ]
    }
   ],
   "source": [
    "vgg_learned_kappa = vgg.BiternionVGG(image_height=image_height,\n",
    "                                     image_width=image_width,\n",
    "                                     n_channels=3,\n",
    "                                     predict_kappa=True)\n",
    "\n",
    "vgg_learned_kappa.model.load_weights('../biternion_net_cluster_logs/best_models/learned_kappa/vgg_bit_vm_likelihood_town.best.weights.h5')\n",
    "\n",
    "results_learned = dict()\n",
    "results_learned['train'] = vgg_learned_kappa.evaluate(xtr, ytr_deg, 'train')\n",
    "results_learned['validation'] = vgg_learned_kappa.evaluate(xval, yval_deg, 'validation')\n",
    "results_learned['test'] = vgg_learned_kappa.evaluate(xte, yte_deg, 'test')\n",
    "\n",
    "learned_preds = vgg_learned_kappa.model.predict(xte)\n",
    "learned_preds_mu_rad = np.deg2rad(bit2deg(learned_preds[:,0:2]))\n",
    "learned_preds_kappa = learned_preds[:,2:]\n",
    "learned_preds_likelihoods = von_mises_log_likelihood_np(yte_bit, learned_preds[:,0:2], learned_preds_kappa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CVAE model (normal training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAAD error (train) : 13.401158 ± 0.209671SEM\n",
      "ELBO (train) : -0.159937 ± 0.007916SEM\n",
      "Approx Log-Likelihood, importance sampling (train) : -0.159711 ± 0.007911SEM\n",
      "KL-div (train) : 0.000001 ± 0.000000SEM\n",
      "MAAD error (validation) : 24.826060 ± 1.161586SEM\n",
      "ELBO (validation) : -0.635584 ± 0.043728SEM\n",
      "Approx Log-Likelihood, importance sampling (validation) : -0.633394 ± 0.043381SEM\n",
      "KL-div (validation) : 0.000001 ± 0.000000SEM\n",
      "MAAD error (test) : 24.265253 ± 1.116603SEM\n",
      "ELBO (test) : -0.676804 ± 0.053363SEM\n",
      "Approx Log-Likelihood, importance sampling (test) : -0.675854 ± 0.053298SEM\n",
      "KL-div (test) : 0.000001 ± 0.000000SEM\n"
     ]
    }
   ],
   "source": [
    "n_samples = 10\n",
    "n_u = 8\n",
    "cvae = CVAE(n_hidden_units=n_u)\n",
    "cvae_ckpt_path = '../biternion_net_cluster_logs/best_models/cvae/original_trainining/cvae.full_model.trial_0.best.weights.hdf5'\n",
    "cvae.full_model.load_weights(cvae_ckpt_path)\n",
    "\n",
    "results_cvae = dict()\n",
    "results_cvae['train'] = cvae.evaluate_multi(xtr, ytr_deg, 'train')\n",
    "results_cvae['validation'] = cvae.evaluate_multi(xval, yval_deg, 'validation', n_samples=n_samples)\n",
    "results_cvae['test'] = cvae.evaluate_multi(xte, yte_deg, 'test', n_samples=n_samples)\n",
    "\n",
    "cvae_preds = cvae.get_multiple_predictions(xte, yte_bit, n_samples=n_samples)\n",
    "cvae_preds_likelihoods = von_mises_log_likelihood_np(yte_bit, cvae_preds['mu_bit_dec'][:,0], cvae_preds['kappa_dec'][:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CVAE model (KL annealing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAAD error (validation) : 26.553490 ± 1.165601SEM\n",
      "ELBO (validation) : -0.900412 ± 0.058183SEM\n",
      "Approx Log-Likelihood, importance sampling (validation) : -0.745836 ± 0.053551SEM\n",
      "KL-div (validation) : 1.189437 ± 0.039002SEM\n",
      "MAAD error (test) : 24.294812 ± 1.101803SEM\n",
      "ELBO (test) : -0.776230 ± 0.056555SEM\n",
      "Approx Log-Likelihood, importance sampling (test) : -0.617326 ± 0.049068SEM\n",
      "KL-div (test) : 1.062494 ± 0.034077SEM\n"
     ]
    }
   ],
   "source": [
    "n_samples = 50\n",
    "n_u = 8\n",
    "cvaekl = CVAE(n_hidden_units=n_u)\n",
    "cvaekl_ckpt_path = '../biternion_net_cluster_logs/best_models/cvae/kl_annealing/cvae.full_model.trial_0.best_likelihood.weights.hdf5'\n",
    "cvaekl.full_model.load_weights(cvaekl_ckpt_path)\n",
    "\n",
    "results_cvaekl = dict()\n",
    "#results_cvaekl['train'] = cvaekl.evaluate_multi(xtr, ytr_deg, 'train', n_samples=n_samples)\n",
    "results_cvaekl['validation'] = cvaekl.evaluate_multi(xval, yval_deg, 'validation', n_samples=n_samples)\n",
    "results_cvaekl['test'] = cvaekl.evaluate_multi(xte, yte_deg, 'test', n_samples=n_samples)\n",
    "\n",
    "cvaekl_preds = cvaekl.get_multiple_predictions(xte, yte_bit, n_samples=n_samples)\n",
    "\n",
    "cvaekl_approx_likelihood = importance_loglikelihood(cvaekl_preds['mu_encoder'], cvaekl_preds['log_sigma_encoder'],\n",
    "                     cvaekl_preds['mu_prior'], cvaekl_preds['log_sigma_prior'],\n",
    "                     cvaekl_preds['u_encoder'],\n",
    "                     cvaekl_preds['mu_bit'], cvaekl_preds['kappa'],\n",
    "                     yte_bit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CVAE model (augmentation with opposite angles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_u = 8\n",
    "# cvaeaug = CVAE(n_hidden_units=n_u)\n",
    "# cvaeaug_ckpt_path = '../biternion_net_cluster_logs/best_models/cvae/opposite_labels_aug/cvae.full_model.trial_0.best.weights.hdf5'\n",
    "# cvaeaug.full_model.load_weights(cvaeaug_ckpt_path)\n",
    "\n",
    "# xtr_aug, ytr_aug_deg = aug_data(xtr, ytr_deg)\n",
    "# xval_aug, yval_aug_deg = aug_data(xval, yval_deg)\n",
    "# xte_aug, yte_aug_deg = aug_data(xte, yte_deg)\n",
    "# ytr_aug_bit = deg2bit(ytr_aug_deg)\n",
    "# yval_aug_bit = deg2bit(yval_aug_deg)\n",
    "# yte_aug_bit = deg2bit(yte_aug_deg)\n",
    "\n",
    "# results_cvaeaug = dict()\n",
    "# results_cvaeaug['train'] = cvaeaug.evaluate(xtr_aug, ytr_aug_deg, 'train')\n",
    "# results_cvaeaug['validation'] = cvaeaug.evaluate(xval_aug, yval_aug_deg, 'validation')\n",
    "# results_cvaeaug['test'] = cvaeaug.evaluate(xte_aug, yte_aug_deg, 'test')\n",
    "\n",
    "# cvaeaug_preds = cvaekl.get_multiple_predictions(xte, yte_bit, n_samples=n_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unconditioned decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAAD error (train) : 43.470157 ± 0.426826SEM\n",
      "ELBO (train) : -1.363755 ± 0.005944SEM\n",
      "Approx Log-Likelihood, importance sampling (train) : -1.362664 ± 0.005904SEM\n",
      "KL-div (train) : 0.015570 ± 0.000251SEM\n",
      "MAAD error (validation) : 48.640293 ± 1.291472SEM\n",
      "ELBO (validation) : -1.430226 ± 0.017024SEM\n",
      "Approx Log-Likelihood, importance sampling (validation) : -1.430310 ± 0.017029SEM\n",
      "KL-div (validation) : 0.016592 ± 0.000793SEM\n",
      "MAAD error (test) : 48.876047 ± 1.418339SEM\n",
      "ELBO (test) : -1.446524 ± 0.018101SEM\n",
      "Approx Log-Likelihood, importance sampling (test) : -1.442873 ± 0.017996SEM\n",
      "KL-div (test) : 0.020262 ± 0.000889SEM\n"
     ]
    }
   ],
   "source": [
    "# from models.cvae_unconditioned_decoder import CVAE as CVAE_unc\n",
    "\n",
    "# n_samples = 10\n",
    "# n_u = 8\n",
    "# cvaeunc = CVAE_unc(n_hidden_units=n_u)\n",
    "# cvaeunc_ckpt_path = '../biternion_net_cluster_logs/best_models/cvae/unconditioned_decoder/cvae.full_model.trial_0.best.weights.hdf5'\n",
    "# cvaeunc.full_model.load_weights(cvaeunc_ckpt_path)\n",
    "\n",
    "# results_cvaeunc = dict()\n",
    "# results_cvaeunc['train'] = cvaeunc.evaluate_multi(xtr, ytr_deg, 'train', n_samples=n_samples)\n",
    "# results_cvaeunc['validation'] = cvaeunc.evaluate_multi(xval, yval_deg, 'validation', n_samples=n_samples)\n",
    "# results_cvaeunc['test'] = cvaeunc.evaluate_multi(xte, yte_deg, 'test', n_samples=n_samples)\n",
    "\n",
    "# cvaeunc_preds = cvaeunc.get_multiple_predictions(xte, yte_bit, n_samples=n_samples)\n",
    "\n",
    "# cvaeunc_approx_likelihood = importance_loglikelihood(cvaeunc_preds['mu_encoder'], cvaeunc_preds['log_sigma_encoder'],\n",
    "#                      cvaeunc_preds['mu_prior'], cvaeunc_preds['log_sigma_prior'],\n",
    "#                      cvaeunc_preds['u_encoder'],\n",
    "#                      cvaeunc_preds['mu_bit'], cvaeunc_preds['kappa'],\n",
    "#                      yte_bit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils.losses import log_bessel_approx_np\n",
    "\n",
    "def vm_pdf(vals, mu_rad, kappa):\n",
    "    return np.exp(kappa * np.cos(vals-mu_rad)) / (2* np.pi * np.exp(log_bessel_approx_np(kappa)))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def plot_vm_dists(fid):\n",
    "    x_vals = np.arange(0, 2*np.pi, 0.01)\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 3, figsize=(25, 5))\n",
    "    \n",
    "    axs[0].imshow(xte[fid])\n",
    "    \n",
    "    def _plt_vgg(axis, mu_rad_preds, kappa_preds, log_likelihoods, method_name):\n",
    "        axis.set_xticks(([0., .5*np.pi, np.pi, 1.5*np.pi, 2*np.pi]))\n",
    "        axis.set_xticklabels([\"$0$\", r\"$\\frac{\\pi}{2}$\", r\"$\\pi$\", r\"$\\frac{3\\pi}{2}$\", r\"$2\\pi$\"]) \n",
    "        axis.set_xlim([-0.001, 2*np.pi+0.001])\n",
    "        axis.plot(x_vals, np.squeeze(vm_pdf(x_vals, mu_rad_preds[fid], kappa_preds[fid])))\n",
    "        axis.axvline(yte_rad[fid], color='red')\n",
    "        axis.set_title(\"%s (logL=%.2f)\" % (method_name, log_likelihoods[fid]))\n",
    "        axis.set_ylim([0, 2.0])\n",
    "        \n",
    "    def _plt_cvae(axis, cvae_mu_rad_preds, cvae_kappa_preds, log_likelihoods, method_name, plot_mixture=False):\n",
    "        axis.set_xticks(([0., .5*np.pi, np.pi, 1.5*np.pi, 2*np.pi]))\n",
    "        axis.set_xticklabels([\"$0$\", r\"$\\frac{\\pi}{2}$\", r\"$\\pi$\", r\"$\\frac{3\\pi}{2}$\", r\"$2\\pi$\"]) \n",
    "        axis.set_xlim([-0.001, 2*np.pi+0.001])\n",
    "        vm_vals = np.zeros([n_samples, x_vals.shape[0]])\n",
    "        if plot_mixture:\n",
    "            for sid in range(0, n_samples):\n",
    "                vm_vals[sid, :] = vm_pdf(x_vals, cvae_mu_rad_preds[fid, sid], cvae_kappa_preds[fid, sid])\n",
    "            axis.plot(x_vals, np.mean(vm_vals, axis=0))\n",
    "        else:\n",
    "            for sid in range(0, n_samples):\n",
    "                axis.plot(x_vals, np.squeeze(vm_pdf(x_vals, cvae_mu_rad_preds[fid, sid], cvae_kappa_preds[fid, sid])))  \n",
    "        axis.axvline(yte_rad[fid], color='red')\n",
    "        axis.set_title(\"%s (logL=%.2f)\" % (method_name, log_likelihoods[fid]))\n",
    "        axis.set_ylim([0, 2.0])\n",
    "        \n",
    "    #_plt_vgg(axs[1], vm_preds_mu_rad, vm_preds_kappa, vm_preds_likelihoods, 'original (Von-Mises loss)')\n",
    "    #_plt_vgg(axs[2], fixed_preds_mu_rad, fixed_preds_kappa, fixed_preds_likelihoods,  'fixed kappa')\n",
    "    #_plt_vgg(axs[3], learned_preds_mu_rad, learned_preds_kappa, learned_preds_likelihoods, 'learned kappa')\n",
    "    #_plt_cvae(axs[4], cvae_preds['mu_rad_dec'], cvae_preds['kappa_dec'], cvae_preds_likelihoods, \"CVAE (normal)\")\n",
    "    #_plt_cvae(axs[5], cvaekl_preds['mu_rad_dec'],  cvaekl_preds['kappa_dec'], cvaekl_approx_likelihood, \"CVAE (KL annealing)\")\n",
    "    #_plt_cvae(axs[6], cvaekl_preds['mu_rad_dec'], cvaekl_preds['kappa_dec'], cvaekl_approx_likelihood, \"CVAE (KL annealing, mixture density)\", plot_mixture=True)\n",
    "    _plt_cvae(axs[1], cvaekl_preds['mu_rad_dec'],  cvaekl_preds['kappa_dec'], cvaekl_approx_likelihood, \"CVAE (Unconditioned decoder)\")\n",
    "    _plt_cvae(axs[2], cvaekl_preds['mu_rad_dec'], cvaekl_preds['kappa_dec'], cvaekl_approx_likelihood, \"CVAE (Unconditioned decoder)\", plot_mixture=True)\n",
    "   \n",
    "    # _plt_cvae(axs[7], cvaeaug_mu_rad_preds,  cvaeaug_kappa_preds, \"CVAE (Random labels augmentation)\")\n",
    "    # _plt_cvae(axs[8], cvaeaug_mu_rad_preds, cvaeaug_kappa_preds, \"CVAE (Random labels augmentation, mixture density)\", plot_mixture=True)\n",
    "    fig.suptitle(\"frame id =%d\" %fid)\n",
    "    #plt.plot((ytr_deg, x2), (y1, y2), 'k-')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "\n",
    "n_samples = 50\n",
    "\n",
    "for fid in range(50, 100):\n",
    "    plot_vm_dists(fid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
